{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/ontologies/anatomy/\"\n",
    "\n",
    "with open(f'{PATH}human.pickle', 'rb') as handle:\n",
    "    human = pickle.load(handle)\n",
    "    \n",
    "with open(f'{PATH}mouse.pickle', 'rb') as handle:\n",
    "    mouse = pickle.load(handle)\n",
    "\n",
    "with open(f'{PATH}entities.pickle', 'rb') as handle:\n",
    "    entities = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0,\n",
       " 2738,\n",
       " 2739,\n",
       " 2740,\n",
       " 2741,\n",
       " 2742,\n",
       " 2743,\n",
       " 2744,\n",
       " 2745,\n",
       " 2746,\n",
       " 2747,\n",
       " 2748,\n",
       " 2749,\n",
       " 2750,\n",
       " 2751,\n",
       " 2752,\n",
       " 2753,\n",
       " 2754,\n",
       " 2755,\n",
       " 2756,\n",
       " 2757,\n",
       " 2758,\n",
       " 2759,\n",
       " 2760,\n",
       " 2761,\n",
       " 2762,\n",
       " 2763,\n",
       " 2764,\n",
       " 2765,\n",
       " 2766,\n",
       " 2767,\n",
       " 2768,\n",
       " 2769,\n",
       " 2770,\n",
       " 2771,\n",
       " 2772,\n",
       " 2773,\n",
       " 2774,\n",
       " 2775,\n",
       " 2776,\n",
       " 2777,\n",
       " 2778,\n",
       " 2779,\n",
       " 2780,\n",
       " 2781,\n",
       " 2782,\n",
       " 2783,\n",
       " 2784,\n",
       " 2785,\n",
       " 2786,\n",
       " 2787,\n",
       " 2788,\n",
       " 2789,\n",
       " 2790,\n",
       " 2791,\n",
       " 2792,\n",
       " 2793,\n",
       " 2794,\n",
       " 2795,\n",
       " 2796,\n",
       " 2797,\n",
       " 2798,\n",
       " 2799,\n",
       " 2800,\n",
       " 2801,\n",
       " 2802,\n",
       " 2803,\n",
       " 2804,\n",
       " 2805,\n",
       " 2806,\n",
       " 2807,\n",
       " 2808,\n",
       " 2809,\n",
       " 2810,\n",
       " 2811,\n",
       " 2812,\n",
       " 2813,\n",
       " 2814,\n",
       " 2815,\n",
       " 2816,\n",
       " 2817,\n",
       " 2818,\n",
       " 2819,\n",
       " 2820,\n",
       " 2821,\n",
       " 2822,\n",
       " 2823,\n",
       " 2824,\n",
       " 2825,\n",
       " 2826,\n",
       " 2827,\n",
       " 2828,\n",
       " 2829,\n",
       " 2830,\n",
       " 2831,\n",
       " 2832,\n",
       " 2833,\n",
       " 2834,\n",
       " 2835,\n",
       " 2836,\n",
       " 2837,\n",
       " 2838,\n",
       " 2839,\n",
       " 2840,\n",
       " 2841,\n",
       " 2842,\n",
       " 2843,\n",
       " 2844,\n",
       " 2845,\n",
       " 2846,\n",
       " 2847,\n",
       " 2848,\n",
       " 2849,\n",
       " 2850,\n",
       " 2851,\n",
       " 2852,\n",
       " 2853,\n",
       " 2854,\n",
       " 2855,\n",
       " 2856,\n",
       " 2857,\n",
       " 2858,\n",
       " 2859,\n",
       " 2860,\n",
       " 2861,\n",
       " 2862,\n",
       " 2863,\n",
       " 2864,\n",
       " 2865,\n",
       " 2866,\n",
       " 2867,\n",
       " 2868,\n",
       " 2869,\n",
       " 2870,\n",
       " 2871,\n",
       " 2872,\n",
       " 2873,\n",
       " 2874,\n",
       " 2875,\n",
       " 2876,\n",
       " 2877,\n",
       " 2878,\n",
       " 2879,\n",
       " 2880,\n",
       " 2881,\n",
       " 2882,\n",
       " 2883,\n",
       " 2884,\n",
       " 2885,\n",
       " 2886,\n",
       " 2887,\n",
       " 2888,\n",
       " 2889,\n",
       " 2890,\n",
       " 2891,\n",
       " 2892,\n",
       " 2893,\n",
       " 2894,\n",
       " 2895,\n",
       " 2896,\n",
       " 2897,\n",
       " 2898,\n",
       " 2899,\n",
       " 2900,\n",
       " 2901,\n",
       " 2902,\n",
       " 2903,\n",
       " 2904,\n",
       " 2905,\n",
       " 2906,\n",
       " 2907,\n",
       " 2908,\n",
       " 2909,\n",
       " 2910,\n",
       " 2911,\n",
       " 2912,\n",
       " 2913,\n",
       " 2914,\n",
       " 2915,\n",
       " 2916,\n",
       " 2917,\n",
       " 2918,\n",
       " 2919,\n",
       " 2920,\n",
       " 2921,\n",
       " 2922,\n",
       " 2923,\n",
       " 2924,\n",
       " 2925,\n",
       " 2926,\n",
       " 2927,\n",
       " 2928,\n",
       " 2929,\n",
       " 2930,\n",
       " 2931,\n",
       " 2932,\n",
       " 2933,\n",
       " 2934,\n",
       " 2935,\n",
       " 2936,\n",
       " 2937,\n",
       " 2938,\n",
       " 2939,\n",
       " 2940,\n",
       " 2941,\n",
       " 2942,\n",
       " 2943,\n",
       " 2944,\n",
       " 2945,\n",
       " 2946,\n",
       " 2947,\n",
       " 2948,\n",
       " 2949,\n",
       " 2950,\n",
       " 2951,\n",
       " 2952,\n",
       " 2953,\n",
       " 2954,\n",
       " 2955,\n",
       " 2956,\n",
       " 2957,\n",
       " 2958,\n",
       " 2959,\n",
       " 2960,\n",
       " 2961,\n",
       " 2962,\n",
       " 2963,\n",
       " 2964,\n",
       " 2965,\n",
       " 2966,\n",
       " 2967,\n",
       " 2968,\n",
       " 2969,\n",
       " 2970,\n",
       " 2971,\n",
       " 2972,\n",
       " 2973,\n",
       " 2974,\n",
       " 2975,\n",
       " 2976,\n",
       " 2977,\n",
       " 2978,\n",
       " 2979,\n",
       " 2980,\n",
       " 2981,\n",
       " 2982,\n",
       " 2983,\n",
       " 2984,\n",
       " 2985,\n",
       " 2986,\n",
       " 2987,\n",
       " 2988,\n",
       " 2989,\n",
       " 2990,\n",
       " 2991,\n",
       " 2992,\n",
       " 2993,\n",
       " 2994,\n",
       " 2995,\n",
       " 2996,\n",
       " 2997,\n",
       " 2998,\n",
       " 2999,\n",
       " 3000,\n",
       " 3001,\n",
       " 3002,\n",
       " 3003,\n",
       " 3004,\n",
       " 3005,\n",
       " 3006,\n",
       " 3007,\n",
       " 3008,\n",
       " 3009,\n",
       " 3010,\n",
       " 3011,\n",
       " 3012,\n",
       " 3013,\n",
       " 3014,\n",
       " 3015,\n",
       " 3016,\n",
       " 3017,\n",
       " 3018,\n",
       " 3019,\n",
       " 3020,\n",
       " 3021,\n",
       " 3022,\n",
       " 3023,\n",
       " 3024,\n",
       " 3025,\n",
       " 3026,\n",
       " 3027,\n",
       " 3028,\n",
       " 3029,\n",
       " 3030,\n",
       " 3031,\n",
       " 3032,\n",
       " 3033,\n",
       " 3034,\n",
       " 3035,\n",
       " 3036,\n",
       " 3037,\n",
       " 3038,\n",
       " 3039,\n",
       " 3040,\n",
       " 3041,\n",
       " 3042,\n",
       " 3043,\n",
       " 3044,\n",
       " 3045,\n",
       " 3046,\n",
       " 3047,\n",
       " 3048,\n",
       " 3049,\n",
       " 3050,\n",
       " 3051,\n",
       " 3052,\n",
       " 3053,\n",
       " 3054,\n",
       " 3055,\n",
       " 3056,\n",
       " 3057,\n",
       " 3058,\n",
       " 3059,\n",
       " 3060,\n",
       " 3061,\n",
       " 3062,\n",
       " 3063,\n",
       " 3064,\n",
       " 3065,\n",
       " 3066,\n",
       " 3067,\n",
       " 3068,\n",
       " 3069,\n",
       " 3070,\n",
       " 3071,\n",
       " 3072,\n",
       " 3073,\n",
       " 3074,\n",
       " 3075,\n",
       " 3076,\n",
       " 3077,\n",
       " 3078,\n",
       " 3079,\n",
       " 3080,\n",
       " 3081,\n",
       " 3082,\n",
       " 3083,\n",
       " 3084,\n",
       " 3085,\n",
       " 3086,\n",
       " 3087,\n",
       " 3088,\n",
       " 3089,\n",
       " 3090,\n",
       " 3091,\n",
       " 3092,\n",
       " 3093,\n",
       " 3094,\n",
       " 3095,\n",
       " 3096,\n",
       " 3097,\n",
       " 3098,\n",
       " 3099,\n",
       " 3100,\n",
       " 3101,\n",
       " 3102,\n",
       " 3103,\n",
       " 3104,\n",
       " 3105,\n",
       " 3106,\n",
       " 3107,\n",
       " 3108,\n",
       " 3109,\n",
       " 3110,\n",
       " 3111,\n",
       " 3112,\n",
       " 3113,\n",
       " 3114,\n",
       " 3115,\n",
       " 3116,\n",
       " 3117,\n",
       " 3118,\n",
       " 3119,\n",
       " 3120,\n",
       " 3121,\n",
       " 3122,\n",
       " 3123,\n",
       " 3124,\n",
       " 3125,\n",
       " 3126,\n",
       " 3127,\n",
       " 3128,\n",
       " 3129,\n",
       " 3130,\n",
       " 3131,\n",
       " 3132,\n",
       " 3133,\n",
       " 3134,\n",
       " 3135,\n",
       " 3136,\n",
       " 3137,\n",
       " 3138,\n",
       " 3139,\n",
       " 3140,\n",
       " 3141,\n",
       " 3142,\n",
       " 3143,\n",
       " 3144,\n",
       " 3145,\n",
       " 3146,\n",
       " 3147,\n",
       " 3148,\n",
       " 3149,\n",
       " 3150,\n",
       " 3151,\n",
       " 3152,\n",
       " 3153,\n",
       " 3154,\n",
       " 3155,\n",
       " 3156,\n",
       " 3157,\n",
       " 3158,\n",
       " 3159,\n",
       " 3160,\n",
       " 3161,\n",
       " 3162,\n",
       " 3163,\n",
       " 3164,\n",
       " 3165,\n",
       " 3166,\n",
       " 3167,\n",
       " 3168,\n",
       " 3169,\n",
       " 3170,\n",
       " 3171,\n",
       " 3172,\n",
       " 3173,\n",
       " 3174,\n",
       " 3175,\n",
       " 3176,\n",
       " 3177,\n",
       " 3178,\n",
       " 3179,\n",
       " 3180,\n",
       " 3181,\n",
       " 3182,\n",
       " 3183,\n",
       " 3184,\n",
       " 3185,\n",
       " 3186,\n",
       " 3187,\n",
       " 3188,\n",
       " 3189,\n",
       " 3190,\n",
       " 3191,\n",
       " 3192,\n",
       " 3193,\n",
       " 3194,\n",
       " 3195,\n",
       " 3196,\n",
       " 3197,\n",
       " 3198,\n",
       " 3199,\n",
       " 3200,\n",
       " 3201,\n",
       " 3202,\n",
       " 3203,\n",
       " 3204,\n",
       " 3205,\n",
       " 3206,\n",
       " 3207,\n",
       " 3208,\n",
       " 3209,\n",
       " 3210,\n",
       " 3211,\n",
       " 3212,\n",
       " 3213,\n",
       " 3214,\n",
       " 3215,\n",
       " 3216,\n",
       " 3217,\n",
       " 3218,\n",
       " 3219,\n",
       " 3220,\n",
       " 3221,\n",
       " 3222,\n",
       " 3223,\n",
       " 3224,\n",
       " 3225,\n",
       " 3226,\n",
       " 3227,\n",
       " 3228,\n",
       " 3229,\n",
       " 3230,\n",
       " 3231,\n",
       " 3232,\n",
       " 3233,\n",
       " 3234,\n",
       " 3235,\n",
       " 3236,\n",
       " 3237,\n",
       " 3238,\n",
       " 3239,\n",
       " 3240,\n",
       " 3241,\n",
       " 3242,\n",
       " 3243,\n",
       " 3244,\n",
       " 3245,\n",
       " 3246,\n",
       " 3247,\n",
       " 3248,\n",
       " 3249,\n",
       " 3250,\n",
       " 3251,\n",
       " 3252,\n",
       " 3253,\n",
       " 3254,\n",
       " 3255,\n",
       " 3256,\n",
       " 3257,\n",
       " 3258,\n",
       " 3259,\n",
       " 3260,\n",
       " 3261,\n",
       " 3262,\n",
       " 3263,\n",
       " 3264,\n",
       " 3265,\n",
       " 3266,\n",
       " 3267,\n",
       " 3268,\n",
       " 3269,\n",
       " 3270,\n",
       " 3271,\n",
       " 3272,\n",
       " 3273,\n",
       " 3274,\n",
       " 3275,\n",
       " 3276,\n",
       " 3277,\n",
       " 3278,\n",
       " 3279,\n",
       " 3280,\n",
       " 3281,\n",
       " 3282,\n",
       " 3283,\n",
       " 3284,\n",
       " 3285,\n",
       " 3286,\n",
       " 3287,\n",
       " 3288,\n",
       " 3289,\n",
       " 3290,\n",
       " 3291,\n",
       " 3292,\n",
       " 3293,\n",
       " 3294,\n",
       " 3295,\n",
       " 3296,\n",
       " 3297,\n",
       " 3298,\n",
       " 3299,\n",
       " 3300,\n",
       " 3301,\n",
       " 3302,\n",
       " 3303,\n",
       " 3304,\n",
       " 3305,\n",
       " 3306,\n",
       " 3307,\n",
       " 3308,\n",
       " 3309,\n",
       " 3310,\n",
       " 3311,\n",
       " 3312,\n",
       " 3313,\n",
       " 3314,\n",
       " 3315,\n",
       " 3316,\n",
       " 3317,\n",
       " 3318,\n",
       " 3319,\n",
       " 3320,\n",
       " 3321,\n",
       " 3322,\n",
       " 3323,\n",
       " 3324,\n",
       " 3325,\n",
       " 3326,\n",
       " 3327,\n",
       " 3328,\n",
       " 3329,\n",
       " 3330,\n",
       " 3331,\n",
       " 3332,\n",
       " 3333,\n",
       " 3334,\n",
       " 3335,\n",
       " 3336,\n",
       " 3337,\n",
       " 3338,\n",
       " 3339,\n",
       " 3340,\n",
       " 3341,\n",
       " 3342,\n",
       " 3343,\n",
       " 3344,\n",
       " 3345,\n",
       " 3346,\n",
       " 3347,\n",
       " 3348,\n",
       " 3349,\n",
       " 3350,\n",
       " 3351,\n",
       " 3352,\n",
       " 3353,\n",
       " 3354,\n",
       " 3355,\n",
       " 3356,\n",
       " 3357,\n",
       " 3358,\n",
       " 3359,\n",
       " 3360,\n",
       " 3361,\n",
       " 3362,\n",
       " 3363,\n",
       " 3364,\n",
       " 3365,\n",
       " 3366,\n",
       " 3367,\n",
       " 3368,\n",
       " 3369,\n",
       " 3370,\n",
       " 3371,\n",
       " 3372,\n",
       " 3373,\n",
       " 3374,\n",
       " 3375,\n",
       " 3376,\n",
       " 3377,\n",
       " 3378,\n",
       " 3379,\n",
       " 3380,\n",
       " 3381,\n",
       " 3382,\n",
       " 3383,\n",
       " 3384,\n",
       " 3385,\n",
       " 3386,\n",
       " 3387,\n",
       " 3388,\n",
       " 3389,\n",
       " 3390,\n",
       " 3391,\n",
       " 3392,\n",
       " 3393,\n",
       " 3394,\n",
       " 3395,\n",
       " 3396,\n",
       " 3397,\n",
       " 3398,\n",
       " 3399,\n",
       " 3400,\n",
       " 3401,\n",
       " 3402,\n",
       " 3403,\n",
       " 3404,\n",
       " 3405,\n",
       " 3406,\n",
       " 3407,\n",
       " 3408,\n",
       " 3409,\n",
       " 3410,\n",
       " 3411,\n",
       " 3412,\n",
       " 3413,\n",
       " 3414,\n",
       " 3415,\n",
       " 3416,\n",
       " 3417,\n",
       " 3418,\n",
       " 3419,\n",
       " 3420,\n",
       " 3421,\n",
       " 3422,\n",
       " 3423,\n",
       " 3424,\n",
       " 3425,\n",
       " 3426,\n",
       " 3427,\n",
       " 3428,\n",
       " 3429,\n",
       " 3430,\n",
       " 3431,\n",
       " 3432,\n",
       " 3433,\n",
       " 3434,\n",
       " 3435,\n",
       " 3436,\n",
       " 3437,\n",
       " 3438,\n",
       " 3439,\n",
       " 3440,\n",
       " 3441,\n",
       " 3442,\n",
       " 3443,\n",
       " 3444,\n",
       " 3445,\n",
       " 3446,\n",
       " 3447,\n",
       " 3448,\n",
       " 3449,\n",
       " 3450,\n",
       " 3451,\n",
       " 3452,\n",
       " 3453,\n",
       " 3454,\n",
       " 3455,\n",
       " 3456,\n",
       " 3457,\n",
       " 3458,\n",
       " 3459,\n",
       " 3460,\n",
       " 3461,\n",
       " 3462,\n",
       " 3463,\n",
       " 3464,\n",
       " 3465,\n",
       " 3466,\n",
       " 3467,\n",
       " 3468,\n",
       " 3469,\n",
       " 3470,\n",
       " 3471,\n",
       " 3472,\n",
       " 3473,\n",
       " 3474,\n",
       " 3475,\n",
       " 3476,\n",
       " 3477,\n",
       " 3478,\n",
       " 3479,\n",
       " 3480,\n",
       " 3481,\n",
       " 3482,\n",
       " 3483,\n",
       " 3484,\n",
       " 3485,\n",
       " 3486,\n",
       " 3487,\n",
       " 3488,\n",
       " 3489,\n",
       " 3490,\n",
       " 3491,\n",
       " 3492,\n",
       " 3493,\n",
       " 3494,\n",
       " 3495,\n",
       " 3496,\n",
       " 3497,\n",
       " 3498,\n",
       " 3499,\n",
       " 3500,\n",
       " 3501,\n",
       " 3502,\n",
       " 3503,\n",
       " 3504,\n",
       " 3505,\n",
       " 3506,\n",
       " 3507,\n",
       " 3508,\n",
       " 3509,\n",
       " 3510,\n",
       " 3511,\n",
       " 3512,\n",
       " 3513,\n",
       " 3514,\n",
       " 3515,\n",
       " 3516,\n",
       " 3517,\n",
       " 3518,\n",
       " 3519,\n",
       " 3520,\n",
       " 3521,\n",
       " 3522,\n",
       " 3523,\n",
       " 3524,\n",
       " 3525,\n",
       " 3526,\n",
       " 3527,\n",
       " 3528,\n",
       " 3529,\n",
       " 3530,\n",
       " 3531,\n",
       " 3532,\n",
       " 3533,\n",
       " 3534,\n",
       " 3535,\n",
       " 3536,\n",
       " 3537,\n",
       " 3538,\n",
       " 3539,\n",
       " 3540,\n",
       " 3541,\n",
       " 3542,\n",
       " 3543,\n",
       " 3544,\n",
       " 3545,\n",
       " 3546,\n",
       " 3547,\n",
       " 3548,\n",
       " 3549,\n",
       " 3550,\n",
       " 3551,\n",
       " 3552,\n",
       " 3553,\n",
       " 3554,\n",
       " 3555,\n",
       " 3556,\n",
       " 3557,\n",
       " 3558,\n",
       " 3559,\n",
       " 3560,\n",
       " 3561,\n",
       " 3562,\n",
       " 3563,\n",
       " 3564,\n",
       " 3565,\n",
       " 3566,\n",
       " 3567,\n",
       " 3568,\n",
       " 3569,\n",
       " 3570,\n",
       " 3571,\n",
       " 3572,\n",
       " 3573,\n",
       " 3574,\n",
       " 3575,\n",
       " 3576,\n",
       " 3577,\n",
       " 3578,\n",
       " 3579,\n",
       " 3580,\n",
       " 3581,\n",
       " 3582,\n",
       " 3583,\n",
       " 3584,\n",
       " 3585,\n",
       " 3586,\n",
       " 3587,\n",
       " 3588,\n",
       " 3589,\n",
       " 3590,\n",
       " 3591,\n",
       " 3592,\n",
       " 3593,\n",
       " 3594,\n",
       " 3595,\n",
       " 3596,\n",
       " 3597,\n",
       " 3598,\n",
       " 3599,\n",
       " 3600,\n",
       " 3601,\n",
       " 3602,\n",
       " 3603,\n",
       " 3604,\n",
       " 3605,\n",
       " 3606,\n",
       " 3607,\n",
       " 3608,\n",
       " 3609,\n",
       " 3610,\n",
       " 3611,\n",
       " 3612,\n",
       " 3613,\n",
       " 3614,\n",
       " 3615,\n",
       " 3616,\n",
       " 3617,\n",
       " 3618,\n",
       " 3619,\n",
       " 3620,\n",
       " 3621,\n",
       " 3622,\n",
       " 3623,\n",
       " 3624,\n",
       " 3625,\n",
       " 3626,\n",
       " 3627,\n",
       " 3628,\n",
       " 3629,\n",
       " 3630,\n",
       " 3631,\n",
       " 3632,\n",
       " 3633,\n",
       " 3634,\n",
       " 3635,\n",
       " 3636,\n",
       " 3637,\n",
       " 3638,\n",
       " 3639,\n",
       " 3640,\n",
       " 3641,\n",
       " 3642,\n",
       " 3643,\n",
       " 3644,\n",
       " 3645,\n",
       " 3646,\n",
       " 3647,\n",
       " 3648,\n",
       " 3649,\n",
       " 3650,\n",
       " 3651,\n",
       " 3652,\n",
       " 3653,\n",
       " 3654,\n",
       " 3655,\n",
       " 3656,\n",
       " 3657,\n",
       " 3658,\n",
       " 3659,\n",
       " 3660,\n",
       " 3661,\n",
       " 3662,\n",
       " 3663,\n",
       " 3664,\n",
       " 3665,\n",
       " 3666,\n",
       " 3667,\n",
       " 3668,\n",
       " 3669,\n",
       " 3670,\n",
       " 3671,\n",
       " 3672,\n",
       " 3673,\n",
       " 3674,\n",
       " 3675,\n",
       " 3676,\n",
       " 3677,\n",
       " 3678,\n",
       " 3679,\n",
       " 3680,\n",
       " 3681,\n",
       " 3682,\n",
       " 3683,\n",
       " 3684,\n",
       " 3685,\n",
       " 3686,\n",
       " 3687,\n",
       " 3688,\n",
       " 3689,\n",
       " 3690,\n",
       " 3691,\n",
       " 3692,\n",
       " 3693,\n",
       " 3694,\n",
       " 3695,\n",
       " 3696,\n",
       " 3697,\n",
       " 3698,\n",
       " 3699,\n",
       " 3700,\n",
       " 3701,\n",
       " 3702,\n",
       " 3703,\n",
       " 3704,\n",
       " 3705,\n",
       " 3706,\n",
       " 3707,\n",
       " 3708,\n",
       " 3709,\n",
       " 3710,\n",
       " 3711,\n",
       " 3712,\n",
       " 3713,\n",
       " 3714,\n",
       " 3715,\n",
       " 3716,\n",
       " 3717,\n",
       " 3718,\n",
       " 3719,\n",
       " 3720,\n",
       " 3721,\n",
       " 3722,\n",
       " 3723,\n",
       " 3724,\n",
       " 3725,\n",
       " 3726,\n",
       " 3727,\n",
       " 3728,\n",
       " 3729,\n",
       " 3730,\n",
       " 3731,\n",
       " 3732,\n",
       " 3733,\n",
       " 3734,\n",
       " 3735,\n",
       " 3736,\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human['human_entities']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "human:\n",
    "type: dict\n",
    "keys: 'edges', list, example\"(2740, 2739)\", #5423 (No bilateral, no 0, first num is parent, second is child)\n",
    "      'parents_of', dict, example\"2739: [2740, 2741]\", #3297 \n",
    "      'children_of', dict, example\"2740: [2739, 2743,...]\", #1071\n",
    "      'human_entities', set, example\"0, 2738,...\", #3299\n",
    "      \n",
    "mouse:\n",
    "type: dict\n",
    "keys: 'edges', list, example\"(3, 2)\", #3444 (No bilateral, no 0, first num is parent, second is child)\n",
    "      'parents_of', dict, example\"2: [3, 4]\", #2736 \n",
    "      'children_of', dict, example\"3: [2, 251,...]\", #915\n",
    "      'mouse_entities', set, example\"0, 1...\", #2738\n",
    "      \n",
    "      \n",
    "entities:\n",
    "type: dict\n",
    "keys: 'all_edges', list, example\"(3, 2)\", #11899 = 5423(human)+3444(mouse)+3032(alignments, but need/2 actually)\n",
    "      'alignments', list, example\"(93, 3629),(3629, 93)...\", #3032 (actually need /2 for bilateral)\n",
    "      'name2idx', dict, example\"'Thing': 0, 'MA_0000001': 1,...\", #6036 (more than label by 1, it is thing:0?)\n",
    "      'idx2name', dict, example\"0: 'Thing', 1: 'MA_0000001',...\", #6036\n",
    "      'label2idx', dict, example\"'mouse anatomy': 1, 'grey matter': 3,...\", #6035\n",
    "      'label2idx', dict, example\"1: 'mouse anatomy', 3: 'grey matter',...\", #6035 \n",
    "      'set', set, example\"0, 1, 2, 3,...\", #6036 = 3299+2738-1(0: Thing)\n",
    "      'align_dict', dict, example\"93: [3629], 3629: [93],...\", #3006 (less 26 compared with alignments, for 26 of dicts' values here have more than 1 value, like \"3048 [246, 247]\" in align_dict == (3048, 246), (3048, 247))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subontology(headnode:int, children_of:dict):\n",
    "    l=0\n",
    "    nlayers=3\n",
    "    \n",
    "    subtree = [[headnode]]\n",
    "    \n",
    "    subtree.append(children_of[headnode])\n",
    "    \n",
    "    # Keep a set of all nodes seen so far, in the form of a list.\n",
    "    set_of_nodes = [headnode]\n",
    "\n",
    "    while l < nlayers:\n",
    "        new_children = []\n",
    "        \n",
    "        # go through all nodes in the current layer \n",
    "        for node in subtree[-1]:\n",
    "            # if the node has not been expanded yet, get that node's children (edges can skip levels)\n",
    "            if node not in set_of_nodes:\n",
    "                set_of_nodes.append(node)\n",
    "                \n",
    "                # some nodes are not in children_of, because they are leaf nodes\n",
    "                if node in children_of:\n",
    "                    new_children = new_children + children_of[node]\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "        next_nodes = [x for x in new_children if x not in set_of_nodes]\n",
    "        subtree.append(list(set(next_nodes)))\n",
    "    \n",
    "        l += 1\n",
    "\n",
    "    return subtree, set(set_of_nodes)\n",
    "\n",
    "m_subtree, m_subset = subontology(11, mouse['children_of']) # limb\n",
    "h_subtree, h_subset = subontology(3030, human['children_of']) # Limb\n",
    "\n",
    "subset = m_subset.union(h_subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_duplicated(sub):\n",
    "    set_of_nodes = []\n",
    "    \n",
    "    for layer in sub:\n",
    "        for node in layer:\n",
    "            if node not in set_of_nodes:\n",
    "                set_of_nodes.append(node)\n",
    "            else:\n",
    "                print(f\"The node {node} is already in the tree.\")\n",
    "                print(\"before proceeding, make sure you got the subontology correct.\")\n",
    "                \n",
    "is_duplicated(h_subtree)\n",
    "is_duplicated(m_subtree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get alignments for subontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subontology_alignments(alignments, subset):\n",
    "    \n",
    "    sub_alignments = []\n",
    "    \n",
    "    for align in alignments:\n",
    "        if align[0] in subset and align[1] in subset:\n",
    "            sub_alignments.append(align)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return sub_alignments\n",
    "\n",
    "sub_alignments = subontology_alignments(entities['alignments'], subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligments the two trees have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get edges within each sub ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dict(_dict:dict, key:int, value:int):\n",
    "    if key in _dict:\n",
    "        _dict[key].append(value) \n",
    "    else:\n",
    "        _dict[key] = [value]\n",
    "\n",
    "def subontology_edges(edges, subset):\n",
    "    \n",
    "    sub_edges = []\n",
    "    parents = {}\n",
    "    children = {}\n",
    "    \n",
    "    for (node1, node2) in edges:\n",
    "        if node1 in subset and node2 in subset:\n",
    "            sub_edges.append((node1, node2))\n",
    "            set_dict(parents, node2, node1)\n",
    "            set_dict(children, node1, node2)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return sub_edges, parents, children\n",
    "\n",
    "sub_mouse, m_parents, m_children = subontology_edges(mouse['edges'], subset)\n",
    "sub_human, h_parents, h_children = subontology_edges(human['edges'], subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligment-edges the two trees have\n",
    "'sub_mouse/sub_human', type:list, include all edges every tree has\n",
    "'parents', type:dict, include parents info for entities in trees\n",
    "'children', type:dict, include children info for entities in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero index the sub ontologies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "just reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize(input_set):\n",
    "    \n",
    "    sorted_set = sorted(list(input_set))\n",
    "    \n",
    "    zeroized_dict = {}\n",
    "    zeroized_set = []\n",
    "    \n",
    "    for item in sorted_set:\n",
    "        zeroized_set.append(len(zeroized_dict))\n",
    "        zeroized_dict[item] = len(zeroized_dict)\n",
    "        \n",
    "        \n",
    "    return zeroized_dict, set(zeroized_set)\n",
    "\n",
    "zeroized_dict, zeroized_set = zeroize(subset)\n",
    "zero_to_orig = dict((v,k) for k,v in zeroized_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize_edges(edges, zd):\n",
    "    \"\"\"zd: dictionary that translates original indeces to zeroized indeces\"\"\"\n",
    "    zeroized_edges = []\n",
    "    \n",
    "    for (node1, node2) in edges:\n",
    "        zeroized_edges.append((zd[node1], zd[node2]))\n",
    "            \n",
    "    return zeroized_edges \n",
    "\n",
    "def zeroize_set(input_set:set, zd):\n",
    "    zeroized_set = [zd[x] for x in input_set]\n",
    "    return set(zeroized_set)\n",
    "\n",
    "def zeroize_other(fam:dict, zd):\n",
    "    \"\"\"Used for zeroizing other parents & children\"\"\"\n",
    "    \n",
    "    zfam = {}\n",
    "    \n",
    "    for (key, values) in fam.items():\n",
    "        for v in values:\n",
    "            set_dict(zfam, zd[key], zd[v])\n",
    "            \n",
    "    return zfam\n",
    "\n",
    "sub_mouse = zeroize_edges(sub_mouse, zeroized_dict)\n",
    "sub_human = zeroize_edges(sub_human, zeroized_dict)\n",
    "sub_alignments = zeroize_edges(sub_alignments, zeroized_dict)\n",
    "\n",
    "m_subset = zeroize_set(m_subset, zeroized_dict)\n",
    "h_subset = zeroize_set(h_subset, zeroized_dict)\n",
    "\n",
    "m_children = zeroize_other(m_children, zeroized_dict)\n",
    "h_children = zeroize_other(h_children, zeroized_dict)\n",
    "\n",
    "m_parents = zeroize_other(m_parents, zeroized_dict)\n",
    "h_parents = zeroize_other(h_parents, zeroized_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligment-edges the two trees have\n",
    "'sub_mouse/sub_human', type:list, include all edges every tree has\n",
    "'parents', type:dict, include parents info for entities in trees\n",
    "'children', type:dict, include children info for entities in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/dev split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get positive data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training edges in the mouse ontology: 227\n",
      "Number of training edges in the human ontology: 44\n"
     ]
    }
   ],
   "source": [
    "tr_m_pos_edges = []\n",
    "tr_h_pos_edges = []\n",
    "\n",
    "# Trainsplit: used to determine how many edges within a tree are going to be in the training set.\n",
    "# 1.0 -> full set of edges in the ontology will be in the training dataset\n",
    "train_split = 1.0\n",
    "\n",
    "# alignmentsplit: choose how many of the alignment edges to include in the training dataset\n",
    "alignment_split = 0.8\n",
    "\n",
    "for edge in sub_mouse:\n",
    "    if np.random.uniform() > (1-train_split):\n",
    "        tr_m_pos_edges.append(edge)\n",
    "    \n",
    "for edge in sub_human:\n",
    "    if np.random.uniform() > (1-train_split):\n",
    "        tr_h_pos_edges.append(edge)\n",
    "\n",
    "if np.floor(len(sub_alignments)*alignment_split)%2 == 1.0:\n",
    "    tr_pos_alignments  = sub_alignments[:int(np.floor(len(sub_alignments)*alignment_split))+1]\n",
    "    dev_pos_alignments = sub_alignments[int(np.floor(len(sub_alignments)*alignment_split))+1:]\n",
    "else:\n",
    "    tr_pos_alignments  = sub_alignments[:int(np.floor(len(sub_alignments)*alignment_split))]\n",
    "    dev_pos_alignments = sub_alignments[int(np.floor(len(sub_alignments)*alignment_split)):]\n",
    "\n",
    "print(\"Number of training edges in the mouse ontology:\", len(tr_m_pos_edges))\n",
    "print(\"Number of training edges in the human ontology:\", len(tr_h_pos_edges))\n",
    "\n",
    "train_positives = tr_m_pos_edges + tr_h_pos_edges + tr_pos_alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True negative alignments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "randomly select an alignment, and replace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siblings(parents:dict, children:dict, node:int):\n",
    "    siblings = []\n",
    "    \n",
    "    # There should only be only one node that doesn't have any parents, the root node\n",
    "    if node in parents:\n",
    "        parents_of_node = parents[node]\n",
    "        \n",
    "        # Cycle through all possible parents of the given node\n",
    "        for p in parents_of_node:\n",
    "            \n",
    "            # if the parent node has any children, add them to the siblings list\n",
    "            if p in children:\n",
    "                siblings = siblings + children[p]\n",
    "                \n",
    "                # remove the node from the siblings list\n",
    "                siblings.remove(node)\n",
    "        \n",
    "        # if there are any siblings, return the list of them\n",
    "        if siblings:\n",
    "            return siblings\n",
    "        \n",
    "        # if there are no siblings, return -1\n",
    "        else:\n",
    "            print(\"Given node does not have any siblings:\", node)\n",
    "            return -1\n",
    "            \n",
    "    # if the node does not have any parents, return -1\n",
    "    else:\n",
    "        print(\"Given node does not have any parents:\", node)\n",
    "        return -1\n",
    "    # ---- \n",
    "\n",
    "def generate_true_neg_alignments(alignments:list, alignment_split:float=0.5, ratio:float=1.0):\n",
    "    \n",
    "    true_negatives = []\n",
    "    numFailures = 0\n",
    "    num_samples = int(len(alignments) * alignment_split * ratio)\n",
    "    \n",
    "    while (len(true_negatives) < num_samples) and (numFailures < 100):\n",
    "        # Select a random alignment within the list of all alignments\n",
    "        rdm_align = random.choice(alignments)\n",
    "\n",
    "        # Pick a node to alter within the randomly chosen alignment \n",
    "        const_node = rdm_align[0]\n",
    "        change_node = rdm_align[1]\n",
    "        \n",
    "        # generate all siblings within the human ontology of the chosen node\n",
    "        if change_node in h_parents:\n",
    "            siblings = get_siblings(h_parents, h_children, change_node)\n",
    "            \n",
    "        # generate all siblings within the mouse ontology of the chosen node\n",
    "        elif change_node in m_parents:\n",
    "            siblings = get_siblings(m_parents, m_children, change_node)\n",
    "            \n",
    "        # This shouldn't be triggered -- every node should have a parent node\n",
    "        # The only possible node that could trigger the below statement is the root node\n",
    "        else:\n",
    "            print(\"Node not found in either Ontology or does not have any parents\")\n",
    "            \n",
    "            \n",
    "        # This error will typically be thrown if the chosen node does not have any siblings\n",
    "        if siblings == -1:\n",
    "            print(\"Error thrown when retrieving siblings\")\n",
    "            \n",
    "        else:\n",
    "            # Choose some random siblings to be make the true negative\n",
    "            negative_alignment = (const_node, random.choice(siblings))\n",
    "            \n",
    "            if negative_alignment in alignments:\n",
    "                numFailures += 1\n",
    "                print(\"Generated negative is an existing alignment:\", negative_alignment, \"OG random:\", rdm_align, siblings)\n",
    "                pass\n",
    "            \n",
    "            elif negative_alignment in true_negatives:\n",
    "                numFailures += 1\n",
    "                print(\"Generated negative already in true_negatives:\", negative_alignment)\n",
    "                pass\n",
    "            \n",
    "            # include this negative alignment in the true_negatives list\n",
    "            else:\n",
    "                true_negatives.append(negative_alignment)\n",
    "                true_negatives.append((negative_alignment[1], const_node))\n",
    "                numFailures = 0\n",
    "                \n",
    "            \n",
    "    return true_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated negative already in true_negatives: (185, 14)\n",
      "Given node does not have any siblings: 180\n",
      "Error thrown when retrieving siblings\n"
     ]
    }
   ],
   "source": [
    "tr_neg_alignments = generate_true_neg_alignments(sub_alignments, alignment_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_true_negatives = generate_true_neg_alignments(sub_alignments, (1-alignment_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate negatives within ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_ratio = 10\n",
    "\n",
    "train_negatives = np.random.choice(list(zero_to_orig.keys()), size=(int(negatives_ratio*len(train_positives)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124,  93],\n",
       "       [155,  35],\n",
       "       [  6, 103],\n",
       "       ...,\n",
       "       [103, 130],\n",
       "       [177,  22],\n",
       "       [ 33, 120]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitive Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_dict = {}\n",
    "\n",
    "for a in sub_alignments:\n",
    "    if a[0] not in alignment_dict:\n",
    "        alignment_dict[a[0]] = [a[1]]\n",
    "    else:\n",
    "        alignment_dict[a[0]].append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_parents(parents_of:dict, node:int):\n",
    "    ancestors = []\n",
    "    \n",
    "    if node in parents_of:\n",
    "        ancestors = ancestors + parents_of[node]\n",
    "        \n",
    "        for a in ancestors:\n",
    "            ancestors = ancestors + get_all_parents(parents_of, a)\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return list(set(ancestors))\n",
    "\n",
    "def get_all_children(children_of:dict, node:int):\n",
    "    descendants = []\n",
    "    \n",
    "    if node in children_of:\n",
    "        # print(node, children_of[node])\n",
    "        descendants = descendants + children_of[node]\n",
    "        \n",
    "        for d in descendants:\n",
    "            descendants = descendants + get_all_children(children_of, d)\n",
    "        # print(\"returning from\", node, descendants)\n",
    "            \n",
    "    else:\n",
    "        # print(node, \"has no children\")\n",
    "        pass\n",
    "    \n",
    "    return list(set(descendants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_in_tr_align(tr_alignments):\n",
    "    tr_align_nodes = []\n",
    "    \n",
    "    for edge in tr_alignments:\n",
    "        for node in edge:\n",
    "            tr_align_nodes.append(node)\n",
    "    \n",
    "    return set(tr_align_nodes)    \n",
    "\n",
    "tr_align_set = nodes_in_tr_align(tr_pos_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitive_closure(entity_set:set, h_parents, m_parents, tr_alignments, USE_OWL_THING:bool=False):\n",
    "    transitive_edges = []\n",
    "    mouse_tc = []\n",
    "    human_tc = []\n",
    "\n",
    "    for _node1 in entity_set:\n",
    "        \n",
    "        if _node1 in m_subset:\n",
    "            parents = get_all_parents(m_parents, _node1)       \n",
    "            other_parents = h_parents\n",
    "        \n",
    "        elif _node1 in h_subset:\n",
    "            parents = get_all_parents(h_parents, _node1)\n",
    "            other_parents = m_parents \n",
    "        \n",
    "        if not parents:\n",
    "            continue\n",
    "        \n",
    "        align_parents = []\n",
    "        # go through all ancestors of the current node (_node1)\n",
    "        for p in parents:\n",
    "            \n",
    "            # if a parent of the node has an alignment, get the parents of that alignment\n",
    "            if p in tr_alignments:\n",
    "                # since some nodes can have multiple alignments, \n",
    "                # go through every alignment and add all parents to the list\n",
    "                for aligned_node in alignment_dict[p]:\n",
    "                    align_parents.append(aligned_node)\n",
    "                    align_parents = align_parents + get_all_parents(other_parents, aligned_node)\n",
    "                    \n",
    "        parents = parents + align_parents\n",
    "        \n",
    "        for _node2 in parents:\n",
    "            transitive_edges.append((_node2, _node1))\n",
    "            \n",
    "            if _node1 in m_subset:\n",
    "                mouse_tc.append((_node2, _node1))\n",
    "                \n",
    "            elif _node1 in h_subset:\n",
    "                human_tc.append((_node2, _node1))\n",
    "        \n",
    "    return transitive_edges, mouse_tc, human_tc\n",
    "\n",
    "tc_pos_edges, mouse_tc, human_tc = transitive_closure(zeroized_set, h_parents, m_parents, tr_align_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_probs = [1/(len(m_subset)-1) for i in range(len(m_subset)) ]\n",
    "human_probs = [1/(len(h_subset)-1) for i in range(len(h_subset)) ]\n",
    "\n",
    "unary_probs = mouse_probs + human_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_negatives_ratio = 2\n",
    "\n",
    "tc_neg_edges = np.random.choice(list(zero_to_orig.keys()), size=(int(negatives_ratio*len(tc_pos_edges)), 2))\n",
    "\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_pos_tc_{alignment_split}.tsv', tc_pos_edges, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_neg_tc_{alignment_split}.tsv', tc_neg_edges, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_pos_{alignment_split}.tsv', train_positives, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_neg_{alignment_split}.tsv', train_negatives, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/dev_align_pos_{alignment_split}.tsv', dev_pos_alignments, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/dev_align_neg_{alignment_split}.tsv', dev_true_negatives, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_align_pos_{alignment_split}.tsv', tr_pos_alignments, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_align_neg_{alignment_split}.tsv', tr_neg_alignments, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pickle = {}\n",
    "mouse_pickle = {}\n",
    "entity_pickle = {}\n",
    "\n",
    "human_pickle['edges'] = sub_human \n",
    "human_pickle['tc'] = human_tc \n",
    "human_pickle['parents_of'] = h_parents\n",
    "human_pickle['children_of'] = h_children\n",
    "human_pickle['human_entities'] = h_subset\n",
    "\n",
    "mouse_pickle['edges'] = sub_mouse\n",
    "mouse_pickle['tc'] = mouse_tc \n",
    "mouse_pickle['parents_of'] = m_parents\n",
    "mouse_pickle['children_of'] = m_children\n",
    "mouse_pickle['mouse_entities'] = m_subset\n",
    "\n",
    "entity_pickle['alignments'] = sub_alignments\n",
    "entity_pickle['all_tc'] = tc_pos_edges\n",
    "entity_pickle['zero_to_orig'] = zero_to_orig\n",
    "entity_pickle['orig_to_zero'] = zeroized_dict\n",
    "entity_pickle['zero_set'] = zeroized_set\n",
    "entity_pickle['set'] = subset\n",
    "entity_pickle['align_dict'] = alignment_dict\n",
    "\n",
    "with open('../data/ontologies/anatomy/subset/human_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(human_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/subset/mouse_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(mouse_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/subset/entities_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(entity_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/ontologies/anatomy/subset/unary/human_unary.tsv', human_probs, delimiter='\\t')\n",
    "np.savetxt('../data/ontologies/anatomy/subset/unary/mouse_unary.tsv', mouse_probs, delimiter='\\t')\n",
    "np.savetxt('../data/ontologies/anatomy/subset/unary/unary.tsv', unary_probs, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
