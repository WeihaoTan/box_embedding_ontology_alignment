{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from boxes import *\n",
    "from learner import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/ontologies/anatomy/'\n",
    "\n",
    "# aligment training split\n",
    "ats = 0.8\n",
    "\n",
    "# Transitive closure\n",
    "Transitive_Closure = False\n",
    "\n",
    "if Transitive_Closure:\n",
    "    tc = \"tc_\"\n",
    "else:\n",
    "    tc = \"\"\n",
    "\n",
    "# Data in unary.tsv are probabilites separated by newlines. The probability on line n is P(n), where n is the id assigned to the nth element.\n",
    "unary_prob = torch.from_numpy(np.loadtxt(f'{PATH}unary/unary.tsv')).float().to(\"cpu\")\n",
    "num_boxes = unary_prob.shape[0]\n",
    "\n",
    "# We're going to use random negative sampling during training, so no need to include negatives in our training data itself\n",
    "train = Probs.load_from_julia(PATH, f'tr_pos_{tc}{ats}.tsv', f'tr_neg_{ats}.tsv', ratio_neg = 0).to(\"cpu\")\n",
    "\n",
    "# The dev set will have a fixed set of negatives, however.\n",
    "dev = Probs.load_from_julia(PATH, f'dev_align_pos_{ats}.tsv', f'dev_align_neg_{ats}.tsv', ratio_neg = 1).to(\"cpu\")\n",
    "\n",
    "# This set is used just for evaluation purposes after training\n",
    "tr_align = Probs.load_from_julia(PATH, f'tr_align_pos_{ats}.tsv', f'tr_align_neg_{ats}.tsv', ratio_neg = 1).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse_eval = Probs.load_from_julia(PATH, 'human_dev_pos.tsv', 'human_dev_neg.tsv', ratio_neg = 1).to(\"cuda\")\n",
    "# human_eval = Probs.load_from_julia(PATH, 'mouse_dev_pos.tsv', 'mouse_dev_neg.tsv', ratio_neg = 1).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 10\n",
    "lr = 1e-2\n",
    "nEpochs = 20\n",
    "rns_ratio = 1\n",
    "box_type = MinMaxSigmoidBoxes\n",
    "use_unary = False\n",
    "unary_weight = 1e-2\n",
    "\n",
    "box_model = BoxModel(\n",
    "    BoxParamType=box_type,\n",
    "    vol_func=soft_volume,\n",
    "    num_models=1,\n",
    "    num_boxes=num_boxes,\n",
    "    dims=dims,\n",
    "    method=\"orig\").to(\"cpu\")\n",
    "\n",
    "#### IF YOU ARE LOADING FROM JULIA WITH ratio_neg=0, train_dl WILL ONLY CONTAIN POSITIVE EXAMPLES\n",
    "#### THIS MEANS YOUR MODEL SHOULD USE NEGATIVE SAMPLING DURING TRAINING\n",
    "train_dl = TensorDataLoader(train, batch_size=2**6, shuffle=True)\n",
    "\n",
    "# mouse_dl = TensorDataLoader(mouse_eval, batch_size=2**6)\n",
    "# human_dl = TensorDataLoader(human_eval, batch_size=2**6)\n",
    "\n",
    "# eval_dl = [mouse_dl, human_dl]\n",
    "\n",
    "opt = torch.optim.Adam(box_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def human_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def mouse_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def align_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "# See boxes/loss_functions.py file for more options. Note that you may have to changed them to fit your use case.\n",
    "# Also note that \"kl_div_sym\" is just binary cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this dataset we had unary probabilities as well as conditional probabilities. Our loss function will be a sum of these, which is provided by the following loss function wrapper:\n",
    "\n",
    "# if use_unary:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss, (unary_weight, mean_unary_kl_loss(unary_prob)))\n",
    "# else:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss)\n",
    "\n",
    "loss_func = LossPieces( mouse_cond_kl_loss, human_cond_kl_loss, (5e-2,align_cond_kl_loss))\n",
    "\n",
    "metrics = [metric_hard_accuracy, metric_hard_f1]\n",
    "align_metrics = [metric_hard_accuracy_align, metric_hard_f1_align, metric_hard_accuracy_align_mean, metric_hard_f1_align_mean]\n",
    "\n",
    "rec_col = RecorderCollection()\n",
    "\n",
    "threshold = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "callbacks = CallbackCollection(\n",
    "    LossCallback(rec_col.train, train),\n",
    "    LossCallback(rec_col.dev, dev),\n",
    "    *(MetricCallback(rec_col.dev, dev, m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.train, train, m) for m in metrics),\n",
    "#     *(MetricCallback(rec_col.onto, human_eval, m) for m in metrics),\n",
    "#     *(MetricCallback(rec_col.onto, mouse_eval, m) for m in metrics),\n",
    "    *(EvalAlignment(rec_col.train_align, tr_align, m) for m in align_metrics),\n",
    "    *(EvalAlignment(rec_col.dev_align, dev, m) for m in align_metrics),\n",
    "    JustGiveMeTheData(rec_col.probs, dev, get_probabilities),\n",
    "    BiasMetric(rec_col.bias, dev, pct_of_align_cond_on_human_as_min),\n",
    "    PlotMetrics(rec_col.dev_roc_plot, dev, roc_plot),\n",
    "    PlotMetrics(rec_col.dev_pr_plot, dev, pr_plot),\n",
    "    PlotMetrics(rec_col.tr_roc_plot, tr_align, roc_plot),\n",
    "    PlotMetrics(rec_col.tr_pr_plot, tr_align, pr_plot),\n",
    "    MetricCallback(rec_col.dev, dev, metric_pearson_r),\n",
    "    MetricCallback(rec_col.train, dev, metric_spearman_r),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.5),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.5),\n",
    "#     GradientClipping(-1000,1000),\n",
    "    RandomNegativeSampling(num_boxes, rns_ratio),\n",
    "    StopIfNaN(),\n",
    ")\n",
    "\n",
    "# l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn)\n",
    "l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn, categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d815b8bc34004bd388c559ad1aaf2189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Overall Training:', max=20, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b1adef6a5c495b9304ea174e8cdd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Current Batch:', max=177, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l.train(nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.evaluation(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.train_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.dev_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $$$$_1 refers to mouse, the metrics without a subscript _1, refer to the human ontology\n",
    "\n",
    "rec_col.onto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_col.probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = rec_col.train_align.dataframe\n",
    "\n",
    "fig1 = plt.figure(num=1, figsize=(10,8), dpi=80, facecolor='white')\n",
    "plt.plot(df_train, linewidth=3)\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel(\"Alignment Factor\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(df_train, loc=0)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = rec_col.dev_align.dataframe\n",
    "\n",
    "fig2 = plt.figure(num=2, figsize=(10,8), dpi=80, facecolor='white')\n",
    "plt.plot(df_dev, linewidth=3)\n",
    "plt.ylim((0,1))\n",
    "plt.xlabel(\"Alignment Factor\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend(df_train, loc=0)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3 = plt.figure(num=3, figsize=(10,8), dpi=80, facecolor='white')\n",
    "plt.plot(rec_col.dev_roc_plot.dataframe['fpr'], rec_col.dev_roc_plot.dataframe['tpr'], linewidth=3)\n",
    "plt.plot(rec_col.tr_roc_plot.dataframe['fpr'], rec_col.tr_roc_plot.dataframe['tpr'], color='g', linewidth=3)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='xkcd:orange', linewidth=3)\n",
    "plt.ylim((0,1.05))\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend((\"Box Model - Dev Alignments\", \"Box Model - Train Alignments\", \"No Skill\"), loc=0)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skill_pr = dev.probs[dev.probs==1].float().sum()  / dev.probs.shape[0]\n",
    "\n",
    "fig4 = plt.figure(num=4, figsize=(10,8), dpi=80, facecolor='white')\n",
    "plt.plot(rec_col.dev_pr_plot.dataframe['recall'], rec_col.dev_pr_plot.dataframe['precision'], linewidth=3)\n",
    "plt.plot(rec_col.tr_pr_plot.dataframe['recall'], rec_col.tr_pr_plot.dataframe['precision'], color='g', linewidth=3)\n",
    "plt.plot([0, 1], [no_skill_pr, no_skill_pr], linestyle='--', color='xkcd:orange', linewidth=3)\n",
    "plt.ylim((0,1.05))\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend((\"Box Model - Dev Alignments\", \"Box Model - Train Alignments\", \"No Skill\"), loc=0)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average_min_probability = np.mean(rec_col.probs.dataframe['Minimum Probablity'])\n",
    "# align_pair_probs = np.stack((rec_col.probs.dataframe['Alignment 1 Probablity'], \n",
    "#                              rec_col.probs.dataframe['Alignment 2 Probablity']), axis=1)\n",
    "\n",
    "# average_align_pair_probs = np.mean(align_pair_probs, axis=1)\n",
    "# print(average_align_pair_probs.shape)\n",
    "\n",
    "# fig = plt.figure(figsize=(10,8), dpi=80, facecolor='white')\n",
    "# plt.plot(range(0, 606), rec_col.probs.dataframe['Alignment 1 Probablity'])\n",
    "# plt.plot(range(0, 606), rec_col.probs.dataframe['Alignment 2 Probablity'])\n",
    "# plt.plot(range(0, 606), average_align_pair_probs)\n",
    "# # plt.plot(range(0, 606), rec_col.probs.dataframe['Minimum Probablity'])\n",
    "# # plt.plot([0, 606], [average_min_probability, average_min_probability], linestyle='--')\n",
    "# plt.ylim((0,1))\n",
    "# plt.xlim((200,300))\n",
    "# plt.xlabel(\"Alignment Number\")\n",
    "# plt.ylabel(\"Probability\")\n",
    "# plt.legend((\"Alignment Conditional Probability 1\", \n",
    "#             \"Alignment Conditional Probability 2\", \n",
    "# # #             \"Minimum Probability\", \"Average Minimum Probability\"\n",
    "#            ), loc=0)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(box_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath =  f\"../results/{box_type.__name__}_nEpochs{nEpochs}_lr{lr}_dims{dims}_ratio{rns_ratio}_{tc}split{ats}_Unary{use_unary}{unary_weight}/\"\n",
    "\n",
    "# This is the most naive implementation\n",
    "def save_recorders():\n",
    "    rec_col.learn.dataframe.to_csv(f\"{fpath}learn.csv\")\n",
    "    rec_col.train.dataframe.to_csv(f\"{fpath}train.csv\")\n",
    "    rec_col.dev.dataframe.to_csv(f\"{fpath}dev.csv\")\n",
    "    rec_col.onto.dataframe.to_csv(f\"{fpath}onto.csv\")\n",
    "    rec_col.train_align.dataframe.to_csv(f\"{fpath}train_align.csv\")\n",
    "    rec_col.dev_align.dataframe.to_csv(f\"{fpath}dev_align.csv\")\n",
    "    rec_col.dev_roc_plot.dataframe.to_csv(f\"{fpath}dev_roc_plot.csv\")\n",
    "    rec_col.dev_pr_plot.dataframe.to_csv(f\"{fpath}dev_pr_plot.csv\")\n",
    "    rec_col.tr_roc_plot.dataframe.to_csv(f\"{fpath}tr_roc_plot.csv\")\n",
    "    rec_col.tr_pr_plot.dataframe.to_csv(f\"{fpath}tr_pr_plot.csv\")\n",
    "    rec_col.probs.dataframe.to_csv(f\"{fpath}probs.csv\")\n",
    "    rec_col.bias.dataframe.to_csv(f\"{fpath}bias.csv\")\n",
    "    \n",
    "def save_plots():\n",
    "    fig1.savefig(f\"{fpath}train_alignment_plot.png\")\n",
    "    fig2.savefig(f\"{fpath}dev_alignment_plot.png\")\n",
    "    fig3.savefig(f\"{fpath}roc_curve.png\")\n",
    "    fig4.savefig(f\"{fpath}pr_curve.png\")\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(fpath)\n",
    "except OSError:\n",
    "    print(\"Creation of the directory %s failed\" % fpath)\n",
    "    print(\"Did not save any of the files.\")\n",
    "else:\n",
    "    print(\"Successfully created the directory %s \" % fpath)\n",
    "    print(\"Saving files ...\")\n",
    "    \n",
    "    fmodel = f\"{fpath}model.pth\"\n",
    "    \n",
    "    save_model = {}\n",
    "    save_model['state_dict'] = box_model.state_dict()\n",
    "    save_model['optimizer']  = opt.state_dict()\n",
    "    save_model['nEpochs']  = nEpochs\n",
    "    save_model['recorders'] = rec_col\n",
    "    save_model['train'] = train\n",
    "    save_model['tr_align'] = tr_align\n",
    "    save_model['dev'] = dev\n",
    "    torch.save(save_model, fmodel)\n",
    "    \n",
    "    save_recorders()\n",
    "    save_plots()\n",
    "    \n",
    "    print(\"Save complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
