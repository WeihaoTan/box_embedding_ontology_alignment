{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    .p-Widget.jp-OutputPrompt.jp-OutputArea-prompt:empty {\n",
       "      padding: 0;\n",
       "      border: 0;\n",
       "    }\n",
       "    </style>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from boxes import *\n",
    "from learner import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import wandb\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed) # cpu\n",
    "    torch.cuda.manual_seed_all(seed)  # gpu\n",
    "    \n",
    "set_seed(42)\n",
    "\n",
    "torch.set_printoptions(precision=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/ontologies/anatomy/'\n",
    "\n",
    "# aligment training split\n",
    "ats = 0.8\n",
    "\n",
    "# Transitive closure\n",
    "Transitive_Closure = False\n",
    "\n",
    "if Transitive_Closure:\n",
    "    tc = \"tc_\"\n",
    "else:\n",
    "    tc = \"\"\n",
    "\n",
    "# Data in unary.tsv are probabilites separated by newlines. The probability on line n is P(n), where n is the id assigned to the nth element.\n",
    "unary_prob = torch.from_numpy(np.loadtxt(f'{PATH}unary/unary.tsv')).float().to(device)\n",
    "num_boxes = unary_prob.shape[0]\n",
    "\n",
    "# We're going to use random negative sampling during training, so no need to include negatives in our training data itself\n",
    "train = Probs.load_from_julia(PATH, f'tr_pos_{tc}{ats}.tsv', f'tr_neg_{ats}.tsv', ratio_neg = 0).to(device)\n",
    "\n",
    "# The dev set will have a fixed set of negatives, however.\n",
    "dev = Probs.load_from_julia(PATH, f'dev_align_pos_{ats}.tsv', f'dev_align_neg_{ats}.tsv', ratio_neg = 1).to(device)\n",
    "\n",
    "# This set is used just for evaluation purposes after training\n",
    "tr_align = Probs.load_from_julia(PATH, f'tr_align_pos_{ats}.tsv', f'tr_align_neg_{ats}.tsv', ratio_neg = 1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ontologies/anatomy/human.pickle', 'rb') as f:\n",
    "    human_pickle = pickle.load(f)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/mouse.pickle', 'rb') as f:\n",
    "    mouse_pickle = pickle.load(f)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/entities.pickle', 'rb') as f:\n",
    "    entity_pickle = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_eval = Probs.load_from_julia(PATH, 'human_dev_pos.tsv', 'human_dev_neg.tsv', ratio_neg = 1).to(device)\n",
    "human_eval = Probs.load_from_julia(PATH, 'mouse_dev_pos.tsv', 'mouse_dev_neg.tsv', ratio_neg = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.nn import Module, Parameter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "################################################\n",
    "# Box Parametrization Layers\n",
    "################################################\n",
    "default_init_min_vol = torch.finfo(torch.float32).tiny\n",
    "\n",
    "\n",
    "\n",
    "class BoxParam(Module):\n",
    "    \"\"\"\n",
    "    An example class for creating a box parametrization.\n",
    "    Don't inherit from this, it is just an example which contains the methods for a class to be used as a BoxParam\n",
    "    layer. Refer to the docstring of the functions when implementing your own BoxParam.\n",
    "\n",
    "    Note: to avoid naming conflicts with min/max functions, we refer to the min coordinate for a box as `z`, and the\n",
    "    max coordinate as `Z`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_models:int, num_boxes:int, dim:int, **kwargs):\n",
    "        \"\"\"\n",
    "        Creates the Parameters used for the representation of boxes.\n",
    "\n",
    "        :param num_models: Number of models\n",
    "        :param num_boxes: Number of boxes\n",
    "        :param dim: Dimension\n",
    "        :param kwargs: Unused for now, but include this for future possible parameters.\n",
    "        \"\"\"\n",
    "        # Remember to call:\n",
    "        super().__init__()\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "    def forward(self, box_indices = slice(None, None, None), **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a Tensor representing the boxes specified by `box_indices` in the form they should be used for training.\n",
    "\n",
    "        :param box_indices: Slice, List, or Tensor of the box indices\n",
    "        :param kwargs: Unused for now, but include this for future possible parameters.\n",
    "        :return: Tensor of shape (model, id, zZ, dim).\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "\n",
    "\n",
    "class Boxes(Module):\n",
    "    \"\"\"\n",
    "    Parametrize boxes using the min coordinate and max coordinate,\n",
    "    initialized to be in the unit hypercube.\n",
    "\n",
    "    self.boxes[model, box, min/max, dim] \\in [0,1]\n",
    "\n",
    "    In this parametrization, the min and max coordinates are explicitly stored\n",
    "    in separate dimensions (as shown above), which means that care must be\n",
    "    taken to preserve max > min while training. (See MinBoxSize Callback.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_models: int, num_boxes: int, dims: int,\n",
    "                 init_min_vol: float = default_init_min_vol, method = \"gibbs\", gibbs_iter: int = 2000, **kwargs):\n",
    "        super().__init__()\n",
    "        self.boxes = Parameter(initialize_boxes_in_unit_cube((num_models, num_boxes), dims, init_min_vol, method, gibbs_iter, **kwargs))\n",
    "\n",
    "    def forward(self, box_indices = slice(None, None, None), **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a Tensor representing the box embeddings specified by box_indices.\n",
    "\n",
    "        :param box_indices: Slice, List, or Tensor of the box indices\n",
    "        :param kwargs: Unused for now, but include this for future possible parameters.\n",
    "        :return: NamedTensor of shape (model, id, zZ, dim).\n",
    "        \"\"\"\n",
    "        return self.boxes[:, box_indices]\n",
    "\n",
    "\n",
    "\n",
    "class MinMaxSigmoidBoxes(Module):\n",
    "    \"\"\"\n",
    "    Parametrize boxes using sigmoid to make them always valid and contained within the unit cube.\n",
    "\n",
    "    self.boxes[model, box, 2, dim] in Reals\n",
    "\n",
    "\n",
    "    In this parametrization, we first convert to the unit cube:\n",
    "\n",
    "    unit_cube_boxes = torch.sigmoid(self.boxes)  # shape: (model, box, 2, dim)\n",
    "\n",
    "    We now select the z/Z coordinates by taking the min/max over axis 2, i.e.\n",
    "\n",
    "    z, _ = torch.min(unit_cube_boxes, dim=2)\n",
    "    Z, _ = torch.max(unit_cube_boxes, dim=2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_models: int, num_boxes: int, dim: int, init_min_vol: float = default_init_min_vol,  **kwargs):\n",
    "        super().__init__()\n",
    "        unit_boxes = Boxes(num_models, num_boxes, dim, init_min_vol, **kwargs)\n",
    "        self._from_UnitBoxes(unit_boxes)\n",
    "        del unit_boxes\n",
    "\n",
    "\n",
    "    def _from_UnitBoxes(self, unit_boxes:Boxes):\n",
    "        boxes = unit_boxes().detach().clone()\n",
    "        self.boxes = Parameter(torch.log(boxes / (1-boxes)))\n",
    "\n",
    "\n",
    "    def forward(self, box_indices = slice(None, None, None), **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a Tensor representing the box embeddings specified by box_indices.\n",
    "\n",
    "        :param box_indices: A NamedTensor of the box indices\n",
    "        :param kwargs: Unused for now, but include this for future possible parameters.\n",
    "        :return: Tensor of shape (model, id, zZ, dim).\n",
    "        \"\"\"\n",
    "        unit_cube_boxes = torch.sigmoid(self.boxes)\n",
    "        z, _ = torch.min(unit_cube_boxes, dim=2)\n",
    "        Z, _ = torch.max(unit_cube_boxes, dim=2)\n",
    "        return torch.stack((z,Z), dim=2)\n",
    "    \n",
    "class AlignmentBoxes(Module):\n",
    "    \"\"\"\n",
    "    Parametrize boxes using sigmoid to make them always valid and contained within the unit cube.\n",
    "\n",
    "    self.boxes[model, box, 2, dim] in Reals\n",
    "\n",
    "\n",
    "    In this parametrization, we first convert to the unit cube:\n",
    "\n",
    "    unit_cube_boxes = torch.sigmoid(self.boxes)  # shape: (model, box, 2, dim)\n",
    "\n",
    "    We now select the z/Z coordinates by taking the min/max over axis 2, i.e.\n",
    "\n",
    "    z, _ = torch.min(unit_cube_boxes, dim=2)\n",
    "    Z, _ = torch.max(unit_cube_boxes, dim=2)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_models: int, num_boxes: int, dim: int, init_min_vol: float = default_init_min_vol,  **kwargs):\n",
    "        super().__init__()\n",
    "        unit_boxes = Boxes(num_models, num_boxes, dim, init_min_vol, **kwargs)\n",
    "        self._from_UnitBoxes(unit_boxes)\n",
    "        self.fc = nn.Linear(dim, dim)\n",
    "        del unit_boxes\n",
    "\n",
    "\n",
    "    def _from_UnitBoxes(self, unit_boxes:Boxes):\n",
    "        boxes = unit_boxes().detach().clone()\n",
    "        self.boxes = Parameter(torch.log(boxes / (1-boxes)))\n",
    "\n",
    "\n",
    "    def forward(self, box_indices = slice(None, None, None), **kwargs) -> Tensor:\n",
    "        \"\"\"\n",
    "        Returns a Tensor representing the box embeddings specified by box_indices.\n",
    "\n",
    "        :param box_indices: A NamedTensor of the box indices\n",
    "        :param kwargs: Unused for now, but include this for future possible parameters.\n",
    "        :return: Tensor of shape (model, id, zZ, dim).\n",
    "        \"\"\"\n",
    "        unit_cube_boxes = torch.sigmoid(self.boxes)\n",
    "        z, _ = torch.min(unit_cube_boxes, dim=2)\n",
    "        Z, _ = torch.max(unit_cube_boxes, dim=2)\n",
    "        z = self.fc(z)\n",
    "        Z = self.fc(Z)\n",
    "        return torch.stack((z,Z), dim=2)\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Downstream Model\n",
    "###############################################\n",
    "\n",
    "class WeightedSum(Module):\n",
    "    def __init__(self, num_models: int) -> None:\n",
    "        super().__init__()\n",
    "        self.weights = Parameter(torch.rand(num_models))\n",
    "\n",
    "    def forward(self, box_vols: Tensor) -> Tensor:\n",
    "        return (F.softmax(self.weights, dim=0).unsqueeze(0) @ box_vols).squeeze()\n",
    "\n",
    "\n",
    "class LogWeightedSum(Module):\n",
    "    def __init__(self, num_models: int) -> None:\n",
    "        super().__init__()\n",
    "        self.weights = Parameter(torch.rand(num_models))\n",
    "\n",
    "    def forward(self, log_box_vols: Tensor) -> Tensor:\n",
    "        return (torch.logsumexp(self.weights + log_box_vols, 0) - torch.logsumexp(self.weights, 0))\n",
    "\n",
    "\n",
    "class BoxModel(Module):\n",
    "    def __init__(self, BoxParamType: type, vol_func: Callable,\n",
    "                 num_models:int, num_boxes:int, dims:int,\n",
    "                 init_min_vol: float = default_init_min_vol, universe_box: Optional[Callable] = None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.box_embedding = BoxParamType(num_models, num_boxes, dims, init_min_vol, **kwargs)\n",
    "        self.vol_func = vol_func\n",
    "\n",
    "        if universe_box is None:\n",
    "            z = torch.zeros(dims)\n",
    "            Z = torch.ones(dims)\n",
    "            self.universe_box = lambda _: torch.stack((z,Z))[None, None]\n",
    "            self.universe_vol = lambda _: self.vol_func(self.universe_box(None)).squeeze()\n",
    "            self.clamp = True\n",
    "        else:\n",
    "            self.universe_box = universe_box\n",
    "            self.universe_vol = lambda b: self.vol_func(self.universe_box(b))\n",
    "            self.clamp = False\n",
    "\n",
    "        self.weights = WeightedSum(num_models)\n",
    "\n",
    "    def forward(self, box_indices: Tensor) -> Dict:\n",
    "        # Unary\n",
    "        box_embeddings_orig = self.box_embedding()\n",
    "        if self.clamp:\n",
    "            box_embeddings = box_embeddings_orig.clamp(0,1)\n",
    "        else:\n",
    "            box_embeddings = box_embeddings_orig\n",
    "\n",
    "        universe_vol = self.universe_vol(box_embeddings)\n",
    "\n",
    "        unary_probs = self.weights(self.vol_func(box_embeddings) / universe_vol)\n",
    "\n",
    "        # Conditional\n",
    "        A = box_embeddings[:, box_indices[:,0]]\n",
    "        B = box_embeddings[:, box_indices[:,1]]\n",
    "        A_int_B_vol = self.weights(self.vol_func(intersection(A, B)) / universe_vol) + torch.finfo(torch.float32).tiny\n",
    "        B_vol = unary_probs[box_indices[:,1]] + torch.finfo(torch.float32).tiny\n",
    "        P_A_given_B = torch.exp(torch.log(A_int_B_vol) - torch.log(B_vol))\n",
    "        \n",
    "        # symmetric same\n",
    "        # print(\"you are in right place!\")\n",
    "#         A = box_embeddings[:, box_indices[:,0]]\n",
    "#         B = box_embeddings[:, box_indices[:,1]]\n",
    "#         A_int_B_vol = self.weights(self.vol_func(intersection(A, B)) / universe_vol) + torch.finfo(torch.float32).tiny\n",
    "#         A_join_B_vol = self.weights(self.vol_func(join(A, B)) / universe_vol) + torch.finfo(torch.float32).tiny\n",
    "#         P_A_given_B = torch.exp(torch.log(A_int_B_vol) - torch.log(A_join_B_vol))\n",
    "\n",
    "        return {\n",
    "            \"unary_probs\": unary_probs,\n",
    "            \"box_embeddings_orig\": box_embeddings_orig,\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"P(A|B)\": P_A_given_B,\n",
    "        }\n",
    "\n",
    "\n",
    "class BoxModelStable(Module):\n",
    "    def __init__(self, BoxParamType: type, log_vol_func: Callable,\n",
    "                 num_models: int, num_boxes: int, dims: int,\n",
    "                 init_min_vol: float = default_init_min_vol,\n",
    "                 universe_box: Optional[Callable] = None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.box_embedding = BoxParamType(num_models, num_boxes, dims, init_min_vol, **kwargs)\n",
    "        self.log_vol_func = log_vol_func\n",
    "\n",
    "        if universe_box is None:\n",
    "            z = torch.zeros(dims)\n",
    "            Z = torch.ones(dims)\n",
    "            self.universe_box = lambda _: torch.stack((z,Z))[None, None]\n",
    "            self.log_universe_vol = lambda _: self.log_vol_func(self.universe_box(None)).squeeze()\n",
    "            self.clamp = True\n",
    "        else:\n",
    "            self.universe_box = universe_box\n",
    "            self.log_universe_vol = lambda b: self.log_vol_func(self.universe_box(b))\n",
    "            self.clamp = False\n",
    "\n",
    "        self.weights = LogWeightedSum(num_models)\n",
    "\n",
    "    def forward(self, box_indices: Tensor) -> Dict:\n",
    "        # Unary\n",
    "        box_embeddings_orig = self.box_embedding()\n",
    "        if self.clamp:\n",
    "            box_embeddings = box_embeddings_orig.clamp(0,1)\n",
    "        else:\n",
    "            box_embeddings = box_embeddings_orig\n",
    "\n",
    "        log_universe_vol = self.log_universe_vol(box_embeddings)\n",
    "\n",
    "        log_unary_probs = self.weights(self.log_vol_func(box_embeddings) -  log_universe_vol)\n",
    "\n",
    "        # Conditional\n",
    "        A = box_embeddings[:, box_indices[:,0]]\n",
    "        B = box_embeddings[:, box_indices[:,1]]\n",
    "        log_A_int_B_vol = self.weights(self.log_vol_func(intersection(A, B)) - log_universe_vol)\n",
    "        log_B_vol = log_unary_probs[box_indices[:,1]]\n",
    "        log_P_A_given_B = log_A_int_B_vol - log_B_vol\n",
    "\n",
    "        return {\n",
    "            \"log_unary_probs\": log_unary_probs,\n",
    "            \"box_embeddings_orig\": box_embeddings_orig,\n",
    "            \"A\": A,\n",
    "            \"B\": B,\n",
    "            \"log P(A|B)\": log_P_A_given_B,\n",
    "            \"P(A|B)\": torch.exp(log_P_A_given_B),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 16\n",
    "lr = 0.07342406890949607\n",
    "rns_ratio = 5\n",
    "#box_type = MinMaxSigmoidBoxes\n",
    "use_unary = False\n",
    "unary_weight = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_box_model = BoxModel(\n",
    "    BoxParamType=MinMaxSigmoidBoxes,\n",
    "    vol_func=soft_volume,\n",
    "    num_models=1,\n",
    "    num_boxes=num_boxes,\n",
    "    dims=dims,\n",
    "    method=\"tree\").to(device)\n",
    "\n",
    "align_box_model = BoxModel(\n",
    "    BoxParamType=AlignmentBoxes,\n",
    "    vol_func=soft_volume,\n",
    "    num_models=1,\n",
    "    num_boxes=num_boxes,\n",
    "    dims=dims,\n",
    "    method=\"tree\").to(device)\n",
    "\n",
    "#### IF YOU ARE LOADING FROM JULIA WITH ratio_neg=0, train_dl WILL ONLY CONTAIN POSITIVE EXAMPLES\n",
    "#### THIS MEANS YOUR MODEL SHOULD USE NEGATIVE SAMPLING DURING TRAINING\n",
    "train_dl = TensorDataLoader(train, batch_size=2**6, shuffle=True)\n",
    "\n",
    "mouse_dl = TensorDataLoader(mouse_eval, batch_size=2**6)\n",
    "human_dl = TensorDataLoader(human_eval, batch_size=2**6)\n",
    "\n",
    "eval_dl = [mouse_dl, human_dl]\n",
    "\n",
    "opt = torch.optim.Adam(box_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def human_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def mouse_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def align_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "# See boxes/loss_functions.py file for more options. Note that you may have to changed them to fit your use case.\n",
    "# Also note that \"kl_div_sym\" is just binary cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "global my_batch_in\n",
    "global my_batch_out\n",
    "my_batch_in = None\n",
    "my_batch_out = None\n",
    "\n",
    "@dataclass\n",
    "class Learner:\n",
    "    train_dl: DataLoader\n",
    "    model: Module\n",
    "    loss_fn: Callable\n",
    "    opt: optim.Optimizer\n",
    "    callbacks: CallbackCollection = field(default_factory=CallbackCollection)\n",
    "    recorder: Recorder = field(default_factory=Recorder)\n",
    "    categories: bool = False\n",
    "    use_wandb: bool = False\n",
    "    reraise_keyboard_interrupt: bool = False\n",
    "    reraise_stop_training_exceptions: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.progress = Progress(0,0,len(self.train_dl))\n",
    "        self.callbacks.learner_post_init(self)\n",
    "\n",
    "    #the split parameter will be used to find human/mouse/align data, so you need change it when using diff dataset(index)\n",
    "    def split_data(self, batch_in, batch_out, split):\n",
    "        category = torch.zeros(size=(batch_in.shape[0],), dtype=int)\n",
    "\n",
    "        batch_class = batch_in > split\n",
    "\n",
    "        for i, (a,b) in enumerate(batch_class):\n",
    "            if not a and not b:\n",
    "                category[i] = 0\n",
    "            elif a and b:\n",
    "                category[i] = 1\n",
    "            else:\n",
    "                category[i] = 2\n",
    "\n",
    "        self.mouse_in = batch_in[category == 0]\n",
    "        self.human_in = batch_in[category == 1]\n",
    "        self.align_in = batch_in[category == 2]\n",
    "\n",
    "        self.mouse_out = batch_out[category == 0]\n",
    "        self.human_out = batch_out[category == 1]\n",
    "        self.align_out = batch_out[category == 2]\n",
    "\n",
    "        # INPUT TO THE MODEL:\n",
    "        data_in = (self.mouse_in, self.human_in, self.align_in)\n",
    "        # TARGET/LABEL:\n",
    "        data_out = (self.mouse_out, self.human_out, self.align_out)\n",
    "\n",
    "        return data_in, data_out\n",
    "\n",
    "    def TensorNaN(self, size:Union[None,List[int], Tuple[int]]=None, device=None, requires_grad:bool=True):\n",
    "        if size is None:    \n",
    "            return torch.tensor(float('nan'), device=device, requires_grad=requires_grad)\n",
    "        else:\n",
    "            return float('nan') * torch.zeros(size=size, device=device, requires_grad=requires_grad)\n",
    "\n",
    "\n",
    "    def train(self, epochs, progress_bar = True):\n",
    "        global my_batch_in\n",
    "        global my_batch_out\n",
    "        try:\n",
    "            self.callbacks.train_begin(self)\n",
    "            for epoch in trange(epochs, desc=\"Overall Training:\", disable=not progress_bar):\n",
    "                self.callbacks.epoch_begin(self)\n",
    "                for iteration, batch in enumerate(tqdm(self.train_dl, desc=\"Current Batch:\", leave=False, disable=not progress_bar)):\n",
    "                    if len(batch) == 2: # KLUDGE\n",
    "                        self.batch_in, self.batch_out = batch\n",
    "                    else:\n",
    "                        self.batch_in = batch[0]\n",
    "                        self.batch_out = None\n",
    "                    self.progress.increment()\n",
    "                    self.callbacks.batch_begin(self)\n",
    "                    self.opt.zero_grad()\n",
    "                    \n",
    "                    if self.categories:\n",
    "                        self.data_in, self.data_out = self.split_data(self.batch_in, self.batch_out, split=2737)\n",
    "#                         #2737 is max mouse index\n",
    "#                         my_batch_in = self.data_in\n",
    "#                         my_batch_out = self.data_out\n",
    "#                         print(\"data_in:\", self.data_in)\n",
    "#                         print(\"data_out:\", self.data_out)\n",
    "#                         assert 1==0\n",
    "                        print(self.model)      \n",
    "                        self.model_pred = [self.model(item) if len(item)>0 else {'P(A|B)':self.TensorNaN(device=self.batch_in.device)} for item in self.data_in]\n",
    "                        self.loss = self.loss_fn(self.model_pred, self.data_out, self, self.recorder, categories=True, use_wandb=self.use_wandb)                        \n",
    "                    else:\n",
    "                        self.model_out = self.model(self.batch_in)\n",
    "                        if self.batch_out is None:\n",
    "                            self.loss = self.loss_fn(self.model_out, self, self.recorder, categories=True, use_wandb=self.use_wandb)\n",
    "                        else:\n",
    "                            self.loss = self.loss_fn(self.model_out, self.batch_out, self, self.recorder, categories=True, use_wandb=self.use_wandb)\n",
    "                        \n",
    "                    # Log metrics inside your training loop\n",
    "                    if self.use_wandb:\n",
    "                        metrics = {'epoch': epoch, 'loss': self.loss}\n",
    "                        wandb.log(metrics)\n",
    "\n",
    "                    # print(self.recorder.dataframe)\n",
    "                    self.loss.backward()\n",
    "                    self.callbacks.backward_end(self)\n",
    "                    self.opt.step()\n",
    "                    self.callbacks.batch_end(self)\n",
    "                # print(self.recorder.dataframe)\n",
    "                \n",
    "                # run evaluating at the end of every epoch\n",
    "                self.evaluation(np.arange(0.1, 1, 0.1))\n",
    "                \n",
    "                \n",
    "                self.callbacks.epoch_end(self)\n",
    "        except StopTrainingException as e:\n",
    "            print(e)\n",
    "            if self.reraise_stop_training_exceptions:\n",
    "                raise e\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Stopped training at {self.progress.partial_epoch_progress()} epochs due to keyboard interrupt.\")\n",
    "            if self.reraise_keyboard_interrupt:\n",
    "                raise KeyboardInterrupt\n",
    "        finally:\n",
    "            self.callbacks.train_end(self)\n",
    "\n",
    "\n",
    "    def evaluation(self, trials, progress_bar=True):\n",
    "        with torch.no_grad():\n",
    "            # self.callbacks.eval_begin(self)\n",
    "            for t in trials:\n",
    "                self.callbacks.eval_align(self, t)\n",
    "            self.callbacks.metric_plots(self)\n",
    "            self.callbacks.bias_metric(self)\n",
    "            self.callbacks.eval_end(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this dataset we had unary probabilities as well as conditional probabilities. Our loss function will be a sum of these, which is provided by the following loss function wrapper:\n",
    "\n",
    "# if use_unary:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss, (unary_weight, mean_unary_kl_loss(unary_prob)))\n",
    "# else:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss)\n",
    "\n",
    "loss_func = LossPieces( (0.05, mouse_cond_kl_loss), (0.05 ,human_cond_kl_loss), (0.05, align_cond_kl_loss))\n",
    "\n",
    "metrics = [metric_hard_accuracy, metric_hard_f1]\n",
    "align_metrics = [metric_hard_accuracy_align, metric_hard_f1_align, metric_hard_accuracy_align_mean, metric_hard_f1_align_mean]\n",
    "\n",
    "rec_col = RecorderCollection()\n",
    "\n",
    "threshold = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "callbacks = CallbackCollection(\n",
    "    LossCallback(rec_col.train, train),\n",
    "    LossCallback(rec_col.dev, dev),\n",
    "    *(MetricCallback(rec_col.dev, dev, \"dev\", m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.train, train, \"train\", m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.onto, human_eval, \"human\", m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.onto, mouse_eval, \"mouse\", m) for m in metrics),\n",
    "    *(EvalAlignment(rec_col.train_align, tr_align, \"train_align\", m) for m in align_metrics),\n",
    "    *(EvalAlignment(rec_col.dev_align, dev, \"dev_align\", m) for m in align_metrics),\n",
    "    JustGiveMeTheData(rec_col.probs, dev, get_probabilities),\n",
    "    BiasMetric(rec_col.bias, dev, pct_of_align_cond_on_human_as_min),\n",
    "    PlotMetrics(rec_col.dev_roc_plot, dev, roc_plot),\n",
    "    PlotMetrics(rec_col.dev_pr_plot, dev, pr_plot),\n",
    "    PlotMetrics(rec_col.tr_roc_plot, tr_align, roc_plot),\n",
    "    PlotMetrics(rec_col.tr_pr_plot, tr_align, pr_plot),\n",
    "    MetricCallback(rec_col.train, train, 'train', metric_pearson_r),\n",
    "    MetricCallback(rec_col.train, train, 'train', metric_spearman_r),\n",
    "    MetricCallback(rec_col.dev, dev, 'dev', metric_pearson_r),\n",
    "    MetricCallback(rec_col.dev, dev, 'dev', metric_spearman_r),\n",
    "#     MetricCallback(rec_col.train, train, 'train', mean_reciprocal_rank),\n",
    "#     MetricCallback(rec_col.dev, dev, 'dev', mean_reciprocal_rank),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.5),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.5),\n",
    "#     GradientClipping(-1000,1000),\n",
    "    RandomNegativeSampling(num_boxes, rns_ratio),\n",
    "    StopIfNaN(),\n",
    ")\n",
    "\n",
    "# l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn)\n",
    "l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn, categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation_dev_metric_hard_accuracy tensor(0.5000000000000000)\n",
      "evaluation_dev_metric_hard_f1 tensor(nan)\n",
      "evaluation_train_metric_hard_accuracy tensor(0.)\n",
      "evaluation_train_metric_hard_f1 tensor(nan)\n",
      "evaluation_human_metric_hard_accuracy tensor(0.5000000000000000)\n",
      "evaluation_human_metric_hard_f1 tensor(nan)\n",
      "evaluation_mouse_metric_hard_accuracy_1 tensor(0.5000000000000000)\n",
      "evaluation_mouse_metric_hard_f1_1 tensor(nan)\n",
      "evaluation_train_metric_pearson_r tensor(0.)\n",
      "evaluation_train_metric_spearman_r nan\n",
      "evaluation_dev_metric_pearson_r tensor(-0.1471888720989227)\n",
      "evaluation_dev_metric_spearman_r -0.29974977098982664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adc73889603465198dfb3fc52d4e8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Overall Training:'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Current Batch:'), FloatProgress(value=0.0, max=177.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "BoxModel(\n",
      "  (box_embedding): MinMaxSigmoidBoxes()\n",
      "  (weights): WeightedSum()\n",
      ")\n",
      "align_evaluation_train_align_0.1_metric_hard_accuracy_align tensor(0.7976092100143433)\n",
      "align_evaluation_train_align_0.1_metric_hard_f1_align tensor(0.7797218561172485)\n",
      "align_evaluation_train_align_0.1_metric_hard_accuracy_align_mean tensor(0.7976092100143433)\n",
      "align_evaluation_train_align_0.1_metric_hard_f1_align_mean tensor(0.7797218561172485)\n",
      "align_evaluation_dev_align_0.1_metric_hard_accuracy_align tensor(0.4884488582611084)\n",
      "align_evaluation_dev_align_0.1_metric_hard_f1_align tensor(0.1483516693115234)\n",
      "align_evaluation_dev_align_0.1_metric_hard_accuracy_align_mean tensor(0.4884488582611084)\n",
      "align_evaluation_dev_align_0.1_metric_hard_f1_align_mean tensor(0.1483516693115234)\n",
      "align_evaluation_train_align_0.2_metric_hard_accuracy_align tensor(0.6100577116012573)\n",
      "align_evaluation_train_align_0.2_metric_hard_f1_align tensor(0.3633916676044464)\n",
      "align_evaluation_train_align_0.2_metric_hard_accuracy_align_mean tensor(0.6100577116012573)\n",
      "align_evaluation_train_align_0.2_metric_hard_f1_align_mean tensor(0.3633916676044464)\n",
      "align_evaluation_dev_align_0.2_metric_hard_accuracy_align tensor(0.5049505233764648)\n",
      "align_evaluation_dev_align_0.2_metric_hard_f1_align tensor(0.0259740278124809)\n",
      "align_evaluation_dev_align_0.2_metric_hard_accuracy_align_mean tensor(0.5049505233764648)\n",
      "align_evaluation_dev_align_0.2_metric_hard_f1_align_mean tensor(0.0259740278124809)\n",
      "align_evaluation_train_align_0.30000000000000004_metric_hard_accuracy_align tensor(0.5234954953193665)\n",
      "align_evaluation_train_align_0.30000000000000004_metric_hard_f1_align tensor(0.0911949723958969)\n",
      "align_evaluation_train_align_0.30000000000000004_metric_hard_accuracy_align_mean tensor(0.5234954953193665)\n",
      "align_evaluation_train_align_0.30000000000000004_metric_hard_f1_align_mean tensor(0.0911949723958969)\n",
      "align_evaluation_dev_align_0.30000000000000004_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.30000000000000004_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.30000000000000004_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.30000000000000004_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.4_metric_hard_accuracy_align tensor(0.5008243918418884)\n",
      "align_evaluation_train_align_0.4_metric_hard_f1_align tensor(0.0032921812962741)\n",
      "align_evaluation_train_align_0.4_metric_hard_accuracy_align_mean tensor(0.5008243918418884)\n",
      "align_evaluation_train_align_0.4_metric_hard_f1_align_mean tensor(0.0032921812962741)\n",
      "align_evaluation_dev_align_0.4_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.4_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.4_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.4_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.5_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.5_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_train_align_0.5_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.5_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_dev_align_0.5_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.5_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.5_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.5_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.6_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.6_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_train_align_0.6_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.6_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_dev_align_0.6_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.6_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.6_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.6_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.7000000000000001_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.7000000000000001_metric_hard_f1_align tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "align_evaluation_train_align_0.7000000000000001_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.7000000000000001_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_dev_align_0.7000000000000001_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.7000000000000001_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.7000000000000001_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.7000000000000001_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.8_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.8_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_train_align_0.8_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.8_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_dev_align_0.8_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.8_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.8_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.8_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_train_align_0.9_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.9_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_train_align_0.9_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_train_align_0.9_metric_hard_f1_align_mean tensor(nan)\n",
      "align_evaluation_dev_align_0.9_metric_hard_accuracy_align tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.9_metric_hard_f1_align tensor(nan)\n",
      "align_evaluation_dev_align_0.9_metric_hard_accuracy_align_mean tensor(0.5000000000000000)\n",
      "align_evaluation_dev_align_0.9_metric_hard_f1_align_mean tensor(nan)\n",
      "evaluation_dev_metric_hard_accuracy tensor(0.5000000000000000)\n",
      "evaluation_dev_metric_hard_f1 tensor(nan)\n",
      "evaluation_train_metric_hard_accuracy tensor(0.)\n",
      "evaluation_train_metric_hard_f1 tensor(nan)\n",
      "evaluation_human_metric_hard_accuracy tensor(0.5000000000000000)\n",
      "evaluation_human_metric_hard_f1 tensor(nan)\n",
      "evaluation_mouse_metric_hard_accuracy_1 tensor(0.5000000000000000)\n",
      "evaluation_mouse_metric_hard_f1_1 tensor(nan)\n",
      "evaluation_train_metric_pearson_r tensor(0.)\n",
      "evaluation_train_metric_spearman_r nan\n",
      "evaluation_dev_metric_pearson_r tensor(-0.1672980040311813)\n",
      "evaluation_dev_metric_spearman_r -0.3105410268671077\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nEpochs = 1\n",
    "l.train(nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2fd6b25fe12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_batch_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "my_batch_in[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_batch_in[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([180, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_batch_in[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
