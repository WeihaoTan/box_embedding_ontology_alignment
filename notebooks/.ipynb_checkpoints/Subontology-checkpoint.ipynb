{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/ontologies/anatomy/\"\n",
    "\n",
    "with open(f'{PATH}human.pickle', 'rb') as handle:\n",
    "    human = pickle.load(handle)\n",
    "    \n",
    "with open(f'{PATH}mouse.pickle', 'rb') as handle:\n",
    "    mouse = pickle.load(handle)\n",
    "\n",
    "with open(f'{PATH}entities.pickle', 'rb') as handle:\n",
    "    entities = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "human:\n",
    "type: dict\n",
    "keys: 'edges', list, example\"(2740, 2739)\", #5423 (No bilateral, no 0, first num is parent, second is child)\n",
    "      'parents_of', dict, example\"2739: [2740, 2741]\", #3297 \n",
    "      'children_of', dict, example\"2740: [2739, 2743,...]\", #1071\n",
    "      'human_entities', set, example\"0, 2738,...\", #3299\n",
    "      \n",
    "mouse:\n",
    "type: dict\n",
    "keys: 'edges', list, example\"(3, 2)\", #3444 (No bilateral, no 0, first num is parent, second is child)\n",
    "      'parents_of', dict, example\"2: [3, 4]\", #2736 \n",
    "      'children_of', dict, example\"3: [2, 251,...]\", #915\n",
    "      'mouse_entities', set, example\"0, 1...\", #2738\n",
    "      \n",
    "      \n",
    "entities:\n",
    "type: dict\n",
    "keys: 'all_edges', list, example\"(3, 2)\", #11899 = 5423(human)+3444(mouse)+3032(alignments, but need/2 actually)\n",
    "      'alignments', list, example\"(93, 3629),(3629, 93)...\", #3032 (actually need /2 for bilateral)\n",
    "      'name2idx', dict, example\"'Thing': 0, 'MA_0000001': 1,...\", #6036 (more than label by 1, it is thing:0?)\n",
    "      'idx2name', dict, example\"0: 'Thing', 1: 'MA_0000001',...\", #6036\n",
    "      'label2idx', dict, example\"'mouse anatomy': 1, 'grey matter': 3,...\", #6035\n",
    "      'label2idx', dict, example\"1: 'mouse anatomy', 3: 'grey matter',...\", #6035 \n",
    "      'set', set, example\"0, 1, 2, 3,...\", #6036 = 3299+2738-1(0: Thing)\n",
    "      'align_dict', dict, example\"93: [3629], 3629: [93],...\", #3006 (less 26 compared with alignments, for 26 of dicts' values here have more than 1 value, like \"3048 [246, 247]\" in align_dict == (3048, 246), (3048, 247))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subontology(headnode:int, children_of:dict):\n",
    "    l=0\n",
    "    nlayers=3\n",
    "    \n",
    "    subtree = [[headnode]]\n",
    "    \n",
    "    subtree.append(children_of[headnode])\n",
    "    \n",
    "    # Keep a set of all nodes seen so far, in the form of a list.\n",
    "    set_of_nodes = [headnode]\n",
    "\n",
    "    while l < nlayers:\n",
    "        new_children = []\n",
    "        \n",
    "        # go through all nodes in the current layer \n",
    "        for node in subtree[-1]:\n",
    "            # if the node has not been expanded yet, get that node's children (edges can skip levels)\n",
    "            if node not in set_of_nodes:\n",
    "                set_of_nodes.append(node)\n",
    "                \n",
    "                # some nodes are not in children_of, because they are leaf nodes\n",
    "                if node in children_of:\n",
    "                    new_children = new_children + children_of[node]\n",
    "                else:\n",
    "                    pass\n",
    "                \n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "        next_nodes = [x for x in new_children if x not in set_of_nodes]\n",
    "        subtree.append(list(set(next_nodes)))\n",
    "    \n",
    "        l += 1\n",
    "\n",
    "    return subtree, set(set_of_nodes)\n",
    "\n",
    "m_subtree, m_subset = subontology(11, mouse['children_of']) # limb\n",
    "h_subtree, h_subset = subontology(3030, human['children_of']) # Limb\n",
    "\n",
    "subset = m_subset.union(h_subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_duplicated(sub):\n",
    "    set_of_nodes = []\n",
    "    \n",
    "    for layer in sub:\n",
    "        for node in layer:\n",
    "            if node not in set_of_nodes:\n",
    "                set_of_nodes.append(node)\n",
    "            else:\n",
    "                print(f\"The node {node} is already in the tree.\")\n",
    "                print(\"before proceeding, make sure you got the subontology correct.\")\n",
    "                \n",
    "is_duplicated(h_subtree)\n",
    "is_duplicated(m_subtree) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get alignments for subontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subontology_alignments(alignments, subset):\n",
    "    \n",
    "    sub_alignments = []\n",
    "    \n",
    "    for align in alignments:\n",
    "        if align[0] in subset and align[1] in subset:\n",
    "            sub_alignments.append(align)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return sub_alignments\n",
    "\n",
    "sub_alignments = subontology_alignments(entities['alignments'], subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligments the two trees have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get edges within each sub ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dict(_dict:dict, key:int, value:int):\n",
    "    if key in _dict:\n",
    "        _dict[key].append(value) \n",
    "    else:\n",
    "        _dict[key] = [value]\n",
    "\n",
    "def subontology_edges(edges, subset):\n",
    "    \n",
    "    sub_edges = []\n",
    "    parents = {}\n",
    "    children = {}\n",
    "    \n",
    "    for (node1, node2) in edges:\n",
    "        if node1 in subset and node2 in subset:\n",
    "            sub_edges.append((node1, node2))\n",
    "            set_dict(parents, node2, node1)\n",
    "            set_dict(children, node1, node2)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return sub_edges, parents, children\n",
    "\n",
    "sub_mouse, m_parents, m_children = subontology_edges(mouse['edges'], subset)\n",
    "sub_human, h_parents, h_children = subontology_edges(human['edges'], subset)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligment-edges the two trees have\n",
    "'sub_mouse/sub_human', type:list, include all edges every tree has\n",
    "'parents', type:dict, include parents info for entities in trees\n",
    "'children', type:dict, include children info for entities in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero index the sub ontologies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "just reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize(input_set):\n",
    "    \n",
    "    sorted_set = sorted(list(input_set))\n",
    "    \n",
    "    zeroized_dict = {}\n",
    "    zeroized_set = []\n",
    "    \n",
    "    for item in sorted_set:\n",
    "        zeroized_set.append(len(zeroized_dict))\n",
    "        zeroized_dict[item] = len(zeroized_dict)\n",
    "        \n",
    "        \n",
    "    return zeroized_dict, set(zeroized_set)\n",
    "\n",
    "zeroized_dict, zeroized_set = zeroize(subset)\n",
    "zero_to_orig = dict((v,k) for k,v in zeroized_dict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroize_edges(edges, zd):\n",
    "    \"\"\"zd: dictionary that translates original indeces to zeroized indeces\"\"\"\n",
    "    zeroized_edges = []\n",
    "    \n",
    "    for (node1, node2) in edges:\n",
    "        zeroized_edges.append((zd[node1], zd[node2]))\n",
    "            \n",
    "    return zeroized_edges \n",
    "\n",
    "def zeroize_set(input_set:set, zd):\n",
    "    zeroized_set = [zd[x] for x in input_set]\n",
    "    return set(zeroized_set)\n",
    "\n",
    "def zeroize_other(fam:dict, zd):\n",
    "    \"\"\"Used for zeroizing other parents & children\"\"\"\n",
    "    \n",
    "    zfam = {}\n",
    "    \n",
    "    for (key, values) in fam.items():\n",
    "        for v in values:\n",
    "            set_dict(zfam, zd[key], zd[v])\n",
    "            \n",
    "    return zfam\n",
    "\n",
    "sub_mouse = zeroize_edges(sub_mouse, zeroized_dict)\n",
    "sub_human = zeroize_edges(sub_human, zeroized_dict)\n",
    "sub_alignments = zeroize_edges(sub_alignments, zeroized_dict)\n",
    "\n",
    "m_subset = zeroize_set(m_subset, zeroized_dict)\n",
    "h_subset = zeroize_set(h_subset, zeroized_dict)\n",
    "\n",
    "m_children = zeroize_other(m_children, zeroized_dict)\n",
    "h_children = zeroize_other(h_children, zeroized_dict)\n",
    "\n",
    "m_parents = zeroize_other(m_parents, zeroized_dict)\n",
    "h_parents = zeroize_other(h_parents, zeroized_dict)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'subtree', type:list, every element is a layer, if len(tree)=5, this is a tree with height=5\n",
    "'subset', type:set, include all entities this tree have\n",
    "'alignments', type:list, include all aligment-edges the two trees have\n",
    "'sub_mouse/sub_human', type:list, include all edges every tree has\n",
    "'parents', type:dict, include parents info for entities in trees\n",
    "'children', type:dict, include children info for entities in trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/dev split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "get positive data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training edges in the mouse ontology: 227\n",
      "Number of training edges in the human ontology: 44\n"
     ]
    }
   ],
   "source": [
    "tr_m_pos_edges = []\n",
    "tr_h_pos_edges = []\n",
    "\n",
    "# Trainsplit: used to determine how many edges within a tree are going to be in the training set.\n",
    "# 1.0 -> full set of edges in the ontology will be in the training dataset\n",
    "train_split = 1.0\n",
    "\n",
    "# alignmentsplit: choose how many of the alignment edges to include in the training dataset\n",
    "alignment_split = 0.8\n",
    "\n",
    "for edge in sub_mouse:\n",
    "    if np.random.uniform() > (1-train_split):\n",
    "        tr_m_pos_edges.append(edge)\n",
    "    \n",
    "for edge in sub_human:\n",
    "    if np.random.uniform() > (1-train_split):\n",
    "        tr_h_pos_edges.append(edge)\n",
    "\n",
    "if np.floor(len(sub_alignments)*alignment_split)%2 == 1.0:\n",
    "    tr_pos_alignments  = sub_alignments[:int(np.floor(len(sub_alignments)*alignment_split))+1]\n",
    "    dev_pos_alignments = sub_alignments[int(np.floor(len(sub_alignments)*alignment_split))+1:]\n",
    "else:\n",
    "    tr_pos_alignments  = sub_alignments[:int(np.floor(len(sub_alignments)*alignment_split))]\n",
    "    dev_pos_alignments = sub_alignments[int(np.floor(len(sub_alignments)*alignment_split)):]\n",
    "\n",
    "print(\"Number of training edges in the mouse ontology:\", len(tr_m_pos_edges))\n",
    "print(\"Number of training edges in the human ontology:\", len(tr_h_pos_edges))\n",
    "\n",
    "train_positives = tr_m_pos_edges + tr_h_pos_edges + tr_pos_alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True negative alignments"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "randomly select an alignment, and replace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siblings(parents:dict, children:dict, node:int):\n",
    "    siblings = []\n",
    "    \n",
    "    # There should only be only one node that doesn't have any parents, the root node\n",
    "    if node in parents:\n",
    "        parents_of_node = parents[node]\n",
    "        \n",
    "        # Cycle through all possible parents of the given node\n",
    "        for p in parents_of_node:\n",
    "            \n",
    "            # if the parent node has any children, add them to the siblings list\n",
    "            if p in children:\n",
    "                siblings = siblings + children[p]\n",
    "                \n",
    "                # remove the node from the siblings list\n",
    "                siblings.remove(node)\n",
    "        \n",
    "        # if there are any siblings, return the list of them\n",
    "        if siblings:\n",
    "            return siblings\n",
    "        \n",
    "        # if there are no siblings, return -1\n",
    "        else:\n",
    "            print(\"Given node does not have any siblings:\", node)\n",
    "            return -1\n",
    "            \n",
    "    # if the node does not have any parents, return -1\n",
    "    else:\n",
    "        print(\"Given node does not have any parents:\", node)\n",
    "        return -1\n",
    "    # ---- \n",
    "\n",
    "def generate_true_neg_alignments(alignments:list, alignment_split:float=0.5, ratio:float=1.0):\n",
    "    \n",
    "    true_negatives = []\n",
    "    numFailures = 0\n",
    "    num_samples = int(len(alignments) * alignment_split * ratio)\n",
    "    \n",
    "    while (len(true_negatives) < num_samples) and (numFailures < 100):\n",
    "        # Select a random alignment within the list of all alignments\n",
    "        rdm_align = random.choice(alignments)\n",
    "\n",
    "        # Pick a node to alter within the randomly chosen alignment \n",
    "        const_node = rdm_align[0]\n",
    "        change_node = rdm_align[1]\n",
    "        \n",
    "        # generate all siblings within the human ontology of the chosen node\n",
    "        if change_node in h_parents:\n",
    "            siblings = get_siblings(h_parents, h_children, change_node)\n",
    "            \n",
    "        # generate all siblings within the mouse ontology of the chosen node\n",
    "        elif change_node in m_parents:\n",
    "            siblings = get_siblings(m_parents, m_children, change_node)\n",
    "            \n",
    "        # This shouldn't be triggered -- every node should have a parent node\n",
    "        # The only possible node that could trigger the below statement is the root node\n",
    "        else:\n",
    "            print(\"Node not found in either Ontology or does not have any parents\")\n",
    "            \n",
    "            \n",
    "        # This error will typically be thrown if the chosen node does not have any siblings\n",
    "        if siblings == -1:\n",
    "            print(\"Error thrown when retrieving siblings\")\n",
    "            \n",
    "        else:\n",
    "            # Choose some random siblings to be make the true negative\n",
    "            negative_alignment = (const_node, random.choice(siblings))\n",
    "            \n",
    "            if negative_alignment in alignments:\n",
    "                numFailures += 1\n",
    "                print(\"Generated negative is an existing alignment:\", negative_alignment, \"OG random:\", rdm_align, siblings)\n",
    "                pass\n",
    "            \n",
    "            elif negative_alignment in true_negatives:\n",
    "                numFailures += 1\n",
    "                print(\"Generated negative already in true_negatives:\", negative_alignment)\n",
    "                pass\n",
    "            \n",
    "            # include this negative alignment in the true_negatives list\n",
    "            else:\n",
    "                true_negatives.append(negative_alignment)\n",
    "                true_negatives.append((negative_alignment[1], const_node))\n",
    "                numFailures = 0\n",
    "                \n",
    "            \n",
    "    return true_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated negative already in true_negatives: (185, 14)\n",
      "Given node does not have any siblings: 180\n",
      "Error thrown when retrieving siblings\n"
     ]
    }
   ],
   "source": [
    "tr_neg_alignments = generate_true_neg_alignments(sub_alignments, alignment_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_true_negatives = generate_true_neg_alignments(sub_alignments, (1-alignment_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate negatives within ontologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_ratio = 10\n",
    "\n",
    "train_negatives = np.random.choice(list(zero_to_orig.keys()), size=(int(negatives_ratio*len(train_positives)), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124,  93],\n",
       "       [155,  35],\n",
       "       [  6, 103],\n",
       "       ...,\n",
       "       [103, 130],\n",
       "       [177,  22],\n",
       "       [ 33, 120]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transitive Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_dict = {}\n",
    "\n",
    "for a in sub_alignments:\n",
    "    if a[0] not in alignment_dict:\n",
    "        alignment_dict[a[0]] = [a[1]]\n",
    "    else:\n",
    "        alignment_dict[a[0]].append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_parents(parents_of:dict, node:int):\n",
    "    ancestors = []\n",
    "    \n",
    "    if node in parents_of:\n",
    "        ancestors = ancestors + parents_of[node]\n",
    "        \n",
    "        for a in ancestors:\n",
    "            ancestors = ancestors + get_all_parents(parents_of, a)\n",
    "            \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return list(set(ancestors))\n",
    "\n",
    "def get_all_children(children_of:dict, node:int):\n",
    "    descendants = []\n",
    "    \n",
    "    if node in children_of:\n",
    "        # print(node, children_of[node])\n",
    "        descendants = descendants + children_of[node]\n",
    "        \n",
    "        for d in descendants:\n",
    "            descendants = descendants + get_all_children(children_of, d)\n",
    "        # print(\"returning from\", node, descendants)\n",
    "            \n",
    "    else:\n",
    "        # print(node, \"has no children\")\n",
    "        pass\n",
    "    \n",
    "    return list(set(descendants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_in_tr_align(tr_alignments):\n",
    "    tr_align_nodes = []\n",
    "    \n",
    "    for edge in tr_alignments:\n",
    "        for node in edge:\n",
    "            tr_align_nodes.append(node)\n",
    "    \n",
    "    return set(tr_align_nodes)    \n",
    "\n",
    "tr_align_set = nodes_in_tr_align(tr_pos_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitive_closure(entity_set:set, h_parents, m_parents, tr_alignments, USE_OWL_THING:bool=False):\n",
    "    transitive_edges = []\n",
    "    mouse_tc = []\n",
    "    human_tc = []\n",
    "\n",
    "    for _node1 in entity_set:\n",
    "        \n",
    "        if _node1 in m_subset:\n",
    "            parents = get_all_parents(m_parents, _node1)       \n",
    "            other_parents = h_parents\n",
    "        \n",
    "        elif _node1 in h_subset:\n",
    "            parents = get_all_parents(h_parents, _node1)\n",
    "            other_parents = m_parents \n",
    "        \n",
    "        if not parents:\n",
    "            continue\n",
    "        \n",
    "        align_parents = []\n",
    "        # go through all ancestors of the current node (_node1)\n",
    "        for p in parents:\n",
    "            \n",
    "            # if a parent of the node has an alignment, get the parents of that alignment\n",
    "            if p in tr_alignments:\n",
    "                # since some nodes can have multiple alignments, \n",
    "                # go through every alignment and add all parents to the list\n",
    "                for aligned_node in alignment_dict[p]:\n",
    "                    align_parents.append(aligned_node)\n",
    "                    align_parents = align_parents + get_all_parents(other_parents, aligned_node)\n",
    "                    \n",
    "        parents = parents + align_parents\n",
    "        \n",
    "        for _node2 in parents:\n",
    "            transitive_edges.append((_node2, _node1))\n",
    "            \n",
    "            if _node1 in m_subset:\n",
    "                mouse_tc.append((_node2, _node1))\n",
    "                \n",
    "            elif _node1 in h_subset:\n",
    "                human_tc.append((_node2, _node1))\n",
    "        \n",
    "    return transitive_edges, mouse_tc, human_tc\n",
    "\n",
    "tc_pos_edges, mouse_tc, human_tc = transitive_closure(zeroized_set, h_parents, m_parents, tr_align_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_probs = [1/(len(m_subset)-1) for i in range(len(m_subset)) ]\n",
    "human_probs = [1/(len(h_subset)-1) for i in range(len(h_subset)) ]\n",
    "\n",
    "unary_probs = mouse_probs + human_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc_negatives_ratio = 2\n",
    "\n",
    "tc_neg_edges = np.random.choice(list(zero_to_orig.keys()), size=(int(negatives_ratio*len(tc_pos_edges)), 2))\n",
    "\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_pos_tc_{alignment_split}.tsv', tc_pos_edges, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_neg_tc_{alignment_split}.tsv', tc_neg_edges, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_pos_{alignment_split}.tsv', train_positives, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_neg_{alignment_split}.tsv', train_negatives, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/dev_align_pos_{alignment_split}.tsv', dev_pos_alignments, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/dev_align_neg_{alignment_split}.tsv', dev_true_negatives, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_align_pos_{alignment_split}.tsv', tr_pos_alignments, delimiter='\\t', fmt='%1.1d')\n",
    "np.savetxt(f'../data/ontologies/anatomy/subset/tr_align_neg_{alignment_split}.tsv', tr_neg_alignments, delimiter='\\t', fmt='%1.1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_pickle = {}\n",
    "mouse_pickle = {}\n",
    "entity_pickle = {}\n",
    "\n",
    "human_pickle['edges'] = sub_human \n",
    "human_pickle['tc'] = human_tc \n",
    "human_pickle['parents_of'] = h_parents\n",
    "human_pickle['children_of'] = h_children\n",
    "human_pickle['human_entities'] = h_subset\n",
    "\n",
    "mouse_pickle['edges'] = sub_mouse\n",
    "mouse_pickle['tc'] = mouse_tc \n",
    "mouse_pickle['parents_of'] = m_parents\n",
    "mouse_pickle['children_of'] = m_children\n",
    "mouse_pickle['mouse_entities'] = m_subset\n",
    "\n",
    "entity_pickle['alignments'] = sub_alignments\n",
    "entity_pickle['all_tc'] = tc_pos_edges\n",
    "entity_pickle['zero_to_orig'] = zero_to_orig\n",
    "entity_pickle['orig_to_zero'] = zeroized_dict\n",
    "entity_pickle['zero_set'] = zeroized_set\n",
    "entity_pickle['set'] = subset\n",
    "entity_pickle['align_dict'] = alignment_dict\n",
    "\n",
    "with open('../data/ontologies/anatomy/subset/human_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(human_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/subset/mouse_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(mouse_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/ontologies/anatomy/subset/entities_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(entity_pickle, handle, protocol=pickle.HIGHEST_PROTOCOL)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../data/ontologies/anatomy/subset/unary/human_unary.tsv', human_probs, delimiter='\\t')\n",
    "np.savetxt('../data/ontologies/anatomy/subset/unary/mouse_unary.tsv', mouse_probs, delimiter='\\t')\n",
    "np.savetxt('../data/ontologies/anatomy/subset/unary/unary.tsv', unary_probs, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
