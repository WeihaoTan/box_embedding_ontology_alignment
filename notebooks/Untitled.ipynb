{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from boxes import *\n",
    "from learner import *\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Learner:\n",
    "    train_dl: DataLoader\n",
    "    model: Module\n",
    "    loss_fn: Callable\n",
    "    opt: optim.Optimizer\n",
    "    callbacks: CallbackCollection = field(default_factory=CallbackCollection)\n",
    "    recorder: Recorder = field(default_factory=Recorder)\n",
    "    categories: bool = False\n",
    "    reraise_keyboard_interrupt: bool = False\n",
    "    reraise_stop_training_exceptions: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.progress = Progress(0,0,len(self.train_dl))\n",
    "        self.callbacks.learner_post_init(self)\n",
    "\n",
    "    #the split parameter will be used to find human/mouse/align data, so you need change it when using diff dataset(index)\n",
    "    def split_data(self, batch_in, batch_out, split):\n",
    "        category = torch.zeros(size=(batch_in.shape[0],), dtype=int)\n",
    "\n",
    "        batch_class = batch_in > split\n",
    "\n",
    "        for i, (a,b) in enumerate(batch_class):\n",
    "            if not a and not b:\n",
    "                category[i] = 0\n",
    "            elif a and b:\n",
    "                category[i] = 1\n",
    "            else:\n",
    "                category[i] = 2\n",
    "\n",
    "        self.mouse_in = batch_in[category == 0]\n",
    "        self.human_in = batch_in[category == 1]\n",
    "        self.align_in = batch_in[category == 2]\n",
    "\n",
    "        self.mouse_out = batch_out[category == 0]\n",
    "        self.human_out = batch_out[category == 1]\n",
    "        self.align_out = batch_out[category == 2]\n",
    "        \n",
    "\n",
    "        # INPUT TO THE MODEL:\n",
    "        data_in = (self.mouse_in, self.human_in, self.align_in)\n",
    "        # TARGET/LABEL:\n",
    "        data_out = (self.mouse_out, self.human_out, self.align_out)\n",
    "\n",
    "        return data_in, data_out\n",
    "\n",
    "    def TensorNaN(self, size:Union[None,List[int], Tuple[int]]=None, device=None, requires_grad:bool=True):\n",
    "        if size is None:    \n",
    "            return torch.tensor(float('nan'), device=device, requires_grad=requires_grad)\n",
    "        else:\n",
    "            return float('nan') * torch.zeros(size=size, device=device, requires_grad=requires_grad)\n",
    "\n",
    "\n",
    "    def train(self, epochs, progress_bar = True):\n",
    "        try:\n",
    "            self.callbacks.train_begin(self)\n",
    "            for epoch in trange(epochs, desc=\"Overall Training:\", disable=not progress_bar):\n",
    "                self.callbacks.epoch_begin(self)\n",
    "                for iteration, batch in enumerate(tqdm(self.train_dl, desc=\"Current Batch:\", leave=False, disable=not progress_bar)):\n",
    "                    if len(batch) == 2: # KLUDGE\n",
    "                        self.batch_in, self.batch_out = batch\n",
    "                    else:\n",
    "                        self.batch_in = batch[0]\n",
    "                        self.batch_out = None\n",
    "                    self.progress.increment()\n",
    "                    self.callbacks.batch_begin(self)\n",
    "                    self.opt.zero_grad()\n",
    "                    # self.test = self.model(torch.empty(0,2))\n",
    "                    # self.loss = self.loss_fn(self.model_out, self.batch_out, self, self.recorder)\n",
    "                    # self.loss = torch.tensor(float('nan'), requires_grad=True).cuda()\n",
    "                    # self.loss.backward()\n",
    "                    # self.opt.step()\n",
    "                    # print(self.batch_in)\n",
    "                    # print(self.batch_in.device)\n",
    "\n",
    "                    if self.categories:\n",
    "                        self.data_in, self.data_out = self.split_data(self.batch_in, self.batch_out, split=2737)                            \n",
    "                        self.model_pred = [self.model(item) if len(item)>0 else {'P(A|B)':self.TensorNaN(device=self.batch_in.device)} for item in self.data_in]\n",
    "                        self.loss = self.loss_fn(self.model_pred, self.data_out, self, self.recorder, categories=True)                        \n",
    "                    else:\n",
    "                        self.model_out = self.model(self.batch_in)\n",
    "                        if self.batch_out is None:\n",
    "                            self.loss = self.loss_fn(self.model_out, self, self.recorder)\n",
    "                        else:\n",
    "                            self.loss = self.loss_fn(self.model_out, self.batch_out, self, self.recorder)\n",
    "                    # print(self.recorder.dataframe)\n",
    "                    self.loss.backward()\n",
    "                    self.callbacks.backward_end(self)\n",
    "                    self.opt.step()\n",
    "                    self.callbacks.batch_end(self)\n",
    "                # print(self.recorder.dataframe)\n",
    "                self.callbacks.epoch_end(self)\n",
    "        except StopTrainingException as e:\n",
    "            print(e)\n",
    "            if self.reraise_stop_training_exceptions:\n",
    "                raise e\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Stopped training at {self.progress.partial_epoch_progress()} epochs due to keyboard interrupt.\")\n",
    "            if self.reraise_keyboard_interrupt:\n",
    "                raise KeyboardInterrupt\n",
    "        finally:\n",
    "            self.callbacks.train_end(self)\n",
    "\n",
    "\n",
    "    def evaluation(self, trials, progress_bar=True):\n",
    "        with torch.no_grad():\n",
    "            # self.callbacks.eval_begin(self)\n",
    "            for t in trials:\n",
    "                self.callbacks.eval_align(self, t)\n",
    "            self.callbacks.metric_plots(self)\n",
    "            self.callbacks.bias_metric(self)\n",
    "            self.callbacks.eval_end(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../data/ontologies/anatomy/'\n",
    "\n",
    "# aligment training split\n",
    "ats = 0.8\n",
    "\n",
    "# Transitive closure\n",
    "Transitive_Closure = False\n",
    "\n",
    "if Transitive_Closure:\n",
    "    tc = \"tc_\"\n",
    "else:\n",
    "    tc = \"\"\n",
    "\n",
    "# Data in unary.tsv are probabilites separated by newlines. The probability on line n is P(n), where n is the id assigned to the nth element.\n",
    "unary_prob = torch.from_numpy(np.loadtxt(f'{PATH}unary/unary.tsv')).float().to(device)\n",
    "num_boxes = unary_prob.shape[0]\n",
    "\n",
    "# We're going to use random negative sampling during training, so no need to include negatives in our training data itself\n",
    "train = Probs.load_from_julia(PATH, f'tr_pos_{tc}{ats}.tsv', f'tr_neg_{ats}.tsv', ratio_neg = 0).to(device)\n",
    "\n",
    "# The dev set will have a fixed set of negatives, however.\n",
    "dev = Probs.load_from_julia(PATH, f'dev_align_pos_{ats}.tsv', f'dev_align_neg_{ats}.tsv', ratio_neg = 1).to(device)\n",
    "\n",
    "# This set is used just for evaluation purposes after training\n",
    "tr_align = Probs.load_from_julia(PATH, f'tr_align_pos_{ats}.tsv', f'tr_align_neg_{ats}.tsv', ratio_neg = 1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_eval = Probs.load_from_julia(PATH, 'human_dev_pos.tsv', 'human_dev_neg.tsv', ratio_neg = 1).to(device)\n",
    "human_eval = Probs.load_from_julia(PATH, 'mouse_dev_pos.tsv', 'mouse_dev_neg.tsv', ratio_neg = 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 10\n",
    "lr = 1e-2\n",
    "nEpochs = 1\n",
    "rns_ratio = 1\n",
    "box_type = MinMaxSigmoidBoxes\n",
    "use_unary = False\n",
    "unary_weight = 1e-2\n",
    "\n",
    "box_model = BoxModel(\n",
    "    BoxParamType=box_type,\n",
    "    vol_func=soft_volume,\n",
    "    num_models=1,\n",
    "    num_boxes=num_boxes,\n",
    "    dims=dims,\n",
    "    method=\"orig\").to(device)\n",
    "\n",
    "#### IF YOU ARE LOADING FROM JULIA WITH ratio_neg=0, train_dl WILL ONLY CONTAIN POSITIVE EXAMPLES\n",
    "#### THIS MEANS YOUR MODEL SHOULD USE NEGATIVE SAMPLING DURING TRAINING\n",
    "train_dl = TensorDataLoader(train, batch_size=2**6, shuffle=True)\n",
    "\n",
    "mouse_dl = TensorDataLoader(mouse_eval, batch_size=2**6)\n",
    "human_dl = TensorDataLoader(human_eval, batch_size=2**6)\n",
    "\n",
    "eval_dl = [mouse_dl, human_dl]\n",
    "\n",
    "opt = torch.optim.Adam(box_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def human_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    kl_loss = kl_div_sym(model_out[\"P(A|B)\"], target, eps)\n",
    "    #print(kl_loss, target, model_out[\"P(A|B)\"])\n",
    "    \n",
    "    [0.2, 0.6, 0.8]\n",
    "    [1, 0, 1]\n",
    "    \n",
    "    (1-0.2)**2 + max(0, is (0.6 - 0) > 0.5)**2 +(1- 0.8)**2\n",
    "    \n",
    "    \n",
    "    kl_loss[kl_loss < 0.5] = 0\n",
    "    return kl_loss.mean()\n",
    "\n",
    "def mouse_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "def align_cond_kl_loss(model_out: ModelOutput, target: Tensor, eps: float = torch.finfo(torch.float32).tiny) -> Tensor:\n",
    "    return kl_div_sym(model_out[\"P(A|B)\"], target, eps).mean()\n",
    "\n",
    "# See boxes/loss_functions.py file for more options. Note that you may have to changed them to fit your use case.\n",
    "# Also note that \"kl_div_sym\" is just binary cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this dataset we had unary probabilities as well as conditional probabilities. Our loss function will be a sum of these, which is provided by the following loss function wrapper:\n",
    "\n",
    "# if use_unary:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss, (unary_weight, mean_unary_kl_loss(unary_prob)))\n",
    "# else:\n",
    "#     loss_func = LossPieces(mean_cond_kl_loss)\n",
    "\n",
    "loss_func = LossPieces( mouse_cond_kl_loss, human_cond_kl_loss, (5e-2,align_cond_kl_loss))\n",
    "\n",
    "metrics = [metric_hard_accuracy, metric_hard_f1]\n",
    "align_metrics = [metric_hard_accuracy_align, metric_hard_f1_align, metric_hard_accuracy_align_mean, metric_hard_f1_align_mean]\n",
    "\n",
    "rec_col = RecorderCollection()\n",
    "\n",
    "threshold = np.arange(0.1, 1, 0.1)\n",
    "\n",
    "callbacks = CallbackCollection(\n",
    "    LossCallback(rec_col.train, train),\n",
    "    LossCallback(rec_col.dev, dev),\n",
    "    *(MetricCallback(rec_col.dev, dev, m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.train, train, m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.onto, human_eval, m) for m in metrics),\n",
    "    *(MetricCallback(rec_col.onto, mouse_eval, m) for m in metrics),\n",
    "    *(EvalAlignment(rec_col.train_align, tr_align, m) for m in align_metrics),\n",
    "    *(EvalAlignment(rec_col.dev_align, dev, m) for m in align_metrics),\n",
    "    JustGiveMeTheData(rec_col.probs, dev, get_probabilities),\n",
    "    BiasMetric(rec_col.bias, dev, pct_of_align_cond_on_human_as_min),\n",
    "    PlotMetrics(rec_col.dev_roc_plot, dev, roc_plot),\n",
    "    PlotMetrics(rec_col.dev_pr_plot, dev, pr_plot),\n",
    "    PlotMetrics(rec_col.tr_roc_plot, tr_align, roc_plot),\n",
    "    PlotMetrics(rec_col.tr_pr_plot, tr_align, pr_plot),\n",
    "    MetricCallback(rec_col.train, train, metric_pearson_r),\n",
    "    MetricCallback(rec_col.train, train, metric_spearman_r),\n",
    "    MetricCallback(rec_col.dev, dev, metric_pearson_r),\n",
    "    MetricCallback(rec_col.dev, dev, metric_spearman_r),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mean_cond_kl_loss\", 0.5),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.25, 10),\n",
    "#     PercentIncreaseEarlyStopping(rec_col.dev, \"mouse_cond_kl_loss\", 0.5),\n",
    "#     GradientClipping(-1000,1000),\n",
    "    RandomNegativeSampling(num_boxes, rns_ratio),\n",
    "    StopIfNaN(),\n",
    ")\n",
    "\n",
    "# l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn)\n",
    "l = Learner(train_dl, box_model, loss_func, opt, callbacks, recorder = rec_col.learn, categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1085, 0.1451, 0.1464,  ..., 0.1352, 0.1426, 0.1748], device='cuda:0') tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0.1327, 0.0641, 0.1866,  ..., 0.0915, 0.1130, 0.1087], device='cuda:0') tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor([0.0675, 0.0901, 0.0950,  ..., 0.2887, 0.1340, 0.0668], device='cuda:0') tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0')\n",
      "tensor(nan, device='cuda:0', requires_grad=True) tensor([], device='cuda:0')\n",
      "tensor(nan, device='cuda:0', requires_grad=True) tensor([], device='cuda:0')\n",
      "tensor([0.0996, 0.0241, 0.2343,  ..., 0.1040, 0.0529, 0.2889], device='cuda:0') tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dfa4a8b36a4b1288345f7a730a45b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Overall Training:', max=1, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bde2d0090a947cc9f5489a03d5cc145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Current Batch:', max=177, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0667, 0.1916, 0.0749, 0.1277, 0.1640, 0.2803, 0.0470, 0.1027, 0.1423,\n",
      "        0.4296, 0.0985, 0.1148, 0.0962, 0.1390, 0.2425, 0.0508, 0.1800, 0.2582,\n",
      "        0.0961, 0.0709, 0.1452, 0.1048, 0.1121, 0.1025, 0.1625],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0437, 0.0577, 0.2693, 0.1327, 0.0960, 0.1109, 0.1232, 0.0494, 0.1658,\n",
      "        0.1972, 0.1139, 0.0366, 0.1843, 0.2693, 0.2171, 0.1095, 0.0901, 0.1784,\n",
      "        0.3320, 0.0852, 0.1878, 0.2385, 0.1995, 0.2427, 0.0861, 0.1127, 0.1747,\n",
      "        0.1443, 0.1495, 0.1969, 0.2526, 0.0873, 0.1112, 0.0570, 0.0879, 0.0585,\n",
      "        0.1864, 0.0892, 0.0706, 0.0771, 0.1178, 0.0779, 0.1057, 0.3299, 0.1228,\n",
      "        0.0854, 0.2385, 0.3048, 0.1310, 0.1673, 0.1172, 0.1574, 0.1397, 0.0490,\n",
      "        0.1304, 0.0698, 0.1039], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0606, 0.0232, 0.1014, 0.1623, 0.1921, 0.2131, 0.1403, 0.1435, 0.1092,\n",
      "        0.1736, 0.2206, 0.0642, 0.2559, 0.1007, 0.0966, 0.1178, 0.1837, 0.1080,\n",
      "        0.2438, 0.1417, 0.1032, 0.1015, 0.0694, 0.3097, 0.1831, 0.1020, 0.0395,\n",
      "        0.1389, 0.2370, 0.1496, 0.1269, 0.0684, 0.0934, 0.1036, 0.0673, 0.2957,\n",
      "        0.1586, 0.0503, 0.0709, 0.1092, 0.1921, 0.0829, 0.1815, 0.0908, 0.0753,\n",
      "        0.0752], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1951, 0.0728, 0.1241, 0.2095, 0.0736, 0.3344, 0.1625, 0.1918, 0.1347,\n",
      "        0.1148, 0.1564, 0.1475, 0.0649, 0.0868, 0.1506, 0.0933, 0.1044, 0.1275,\n",
      "        0.1257, 0.2814, 0.0774, 0.0931, 0.0770, 0.1538, 0.1067, 0.2077, 0.1695,\n",
      "        0.1041, 0.0447], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1391, 0.2504, 0.1663, 0.1069, 0.0298, 0.0682, 0.1992, 0.2200, 0.2346,\n",
      "        0.1244, 0.2260, 0.0871, 0.1367, 0.1490, 0.0679, 0.1589, 0.0756, 0.1411,\n",
      "        0.1067, 0.1957, 0.1277, 0.1185, 0.1200, 0.0408, 0.1514, 0.1082, 0.1119,\n",
      "        0.1428, 0.0971, 0.1632, 0.0708, 0.1214, 0.3677, 0.1215, 0.0490, 0.1224,\n",
      "        0.3885, 0.3875, 0.1334, 0.1080, 0.1276, 0.0999, 0.0881, 0.1438, 0.2506,\n",
      "        0.1292, 0.2330, 0.2609, 0.1340, 0.1364, 0.2025, 0.1798, 0.1884],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.2093, 0.0305, 0.3205, 0.1845, 0.1396, 0.0939, 0.1562, 0.2106, 0.0583,\n",
      "        0.0618, 0.0814, 0.0775, 0.2192, 0.2676, 0.0512, 0.1193, 0.0423, 0.0509,\n",
      "        0.1041, 0.1967, 0.4134, 0.0622, 0.0436, 0.1845, 0.1227, 0.1050, 0.0683,\n",
      "        0.2049, 0.3087, 0.1530, 0.0235, 0.0965, 0.1552, 0.1844, 0.1114, 0.1720,\n",
      "        0.2095, 0.1081, 0.0371, 0.1039, 0.0743, 0.0519, 0.1663, 0.0850, 0.1877,\n",
      "        0.1097], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0611, 0.0677, 0.3188, 0.1271, 0.0676, 0.3282, 0.3608, 0.2037, 0.0930,\n",
      "        0.3551, 0.1515, 0.1576, 0.3112, 0.3543, 0.2601, 0.1635, 0.1880, 0.0976,\n",
      "        0.1755, 0.1829, 0.2127, 0.1600, 0.1606, 0.2681, 0.2341, 0.2193],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0969, 0.1208, 0.1648, 0.0984, 0.1458, 0.0764, 0.1403, 0.1867, 0.1213,\n",
      "        0.1097, 0.1059, 0.1695, 0.1225, 0.3574, 0.1679, 0.3137, 0.2234, 0.0482,\n",
      "        0.1775, 0.0897, 0.1619, 0.1155, 0.0853, 0.0585, 0.2699, 0.0981, 0.2597,\n",
      "        0.1399, 0.1317, 0.1023, 0.3385, 0.1197, 0.1167, 0.2153, 0.1419, 0.0867,\n",
      "        0.1942, 0.1628, 0.1355, 0.1002, 0.2144, 0.0776, 0.1034, 0.1242, 0.0588,\n",
      "        0.2128, 0.0761, 0.1518, 0.1843, 0.0953, 0.2503], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.0782, 0.3528, 0.1163, 0.0671, 0.2276, 0.0551, 0.1157, 0.1497, 0.1327,\n",
      "        0.1230, 0.3379, 0.0777, 0.1781, 0.0807, 0.2064, 0.2912, 0.1103, 0.2099,\n",
      "        0.0599, 0.1036, 0.2360, 0.3439, 0.1855, 0.2147, 0.1541, 0.2597, 0.1007,\n",
      "        0.1017, 0.1021, 0.1060, 0.0740, 0.0989, 0.0888, 0.2193, 0.1508, 0.2087,\n",
      "        0.2031, 0.1260, 0.4053, 0.2228, 0.1709, 0.1097, 0.1457, 0.1321, 0.1073,\n",
      "        0.1972, 0.1987, 0.1456, 0.2485, 0.0555, 0.3982], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.2258, 0.1019, 0.1155, 0.2737, 0.1908, 0.2167, 0.1807, 0.2597, 0.0719,\n",
      "        0.1429, 0.1543, 0.1423, 0.1049, 0.0961, 0.0549, 0.3654, 0.2579, 0.1325,\n",
      "        0.2732, 0.2288, 0.3291, 0.1597, 0.1192, 0.2416, 0.1092, 0.0650, 0.1357,\n",
      "        0.2219, 0.1497], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0427, 0.0774, 0.0751, 0.1790, 0.2090, 0.1012, 0.1628, 0.0414, 0.0988,\n",
      "        0.0931, 0.0980, 0.2148, 0.2406, 0.0735, 0.0373, 0.0780, 0.1197, 0.0430,\n",
      "        0.1749, 0.1889, 0.0943, 0.0684, 0.0696, 0.1430, 0.0513, 0.0720, 0.4373,\n",
      "        0.1473, 0.0573, 0.0938, 0.1209, 0.1264, 0.1958, 0.0999, 0.1274, 0.0888,\n",
      "        0.0911, 0.2118, 0.2015, 0.2010, 0.0616, 0.1029, 0.1044, 0.0824, 0.2445,\n",
      "        0.1107, 0.1357, 0.2400, 0.1560, 0.1232, 0.1812, 0.1798, 0.1286, 0.0709,\n",
      "        0.1140, 0.1301, 0.1074, 0.2819, 0.0514], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1212, 0.2872, 0.2476, 0.2283, 0.1612, 0.1190, 0.3064, 0.0415, 0.2706,\n",
      "        0.0734, 0.2917, 0.1482, 0.0672, 0.0442, 0.2995, 0.0982, 0.2551, 0.0915,\n",
      "        0.1646, 0.1252, 0.1293, 0.0675, 0.1755, 0.1461, 0.2907, 0.0601, 0.0331,\n",
      "        0.2447, 0.0611, 0.2786, 0.1582, 0.1441, 0.2698, 0.1094, 0.1452, 0.1033,\n",
      "        0.0550, 0.1814, 0.1097, 0.2522], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.2040, 0.1056, 0.1626, 0.0897, 0.1332, 0.4483, 0.1246, 0.0858, 0.1931,\n",
      "        0.1275, 0.1401, 0.1696, 0.2471, 0.0522, 0.2113, 0.0387, 0.0599, 0.1551,\n",
      "        0.1019, 0.2106, 0.1438, 0.1907, 0.1983, 0.2664, 0.1983, 0.2341, 0.0845,\n",
      "        1.0000, 0.2371], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1436, 0.1497, 0.0564, 0.0743, 0.2399, 0.1145, 0.1478, 0.2087, 0.3181,\n",
      "        0.2433, 0.2387, 0.1442, 0.2350, 0.1779, 0.1786, 0.1517, 0.1929, 0.3131,\n",
      "        0.1704, 0.2562, 0.1267, 0.1087, 0.2504, 0.2236, 0.1223, 0.0857, 0.3405,\n",
      "        0.1136, 0.1176, 0.1019, 0.0735, 0.1113, 0.0758, 0.1363, 0.0435, 0.1093,\n",
      "        0.0941, 0.4449, 0.0953, 0.1114, 0.0783, 0.1901, 0.1454, 0.1312, 0.0716,\n",
      "        0.2290, 0.1459, 0.1365, 0.1132, 0.2180, 0.2208, 0.1600, 0.3325],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.2386, 0.1272, 0.3231, 0.0934, 0.1062, 0.0591, 0.1392, 0.1981, 0.1148,\n",
      "        0.2199, 0.1166, 0.1544, 0.2720, 0.1755, 0.1833, 0.1523, 0.1604, 0.2708,\n",
      "        0.0528, 0.1970, 0.2461, 0.1211, 0.2373, 0.1536, 0.1194, 0.1526, 0.2028,\n",
      "        0.3217, 0.0765, 0.2306, 0.1446, 0.2374, 0.1152, 0.2601, 0.1474, 0.2269,\n",
      "        0.0858, 0.1012, 0.0372, 0.0752, 0.3101, 0.1735, 0.0609, 0.0881, 0.1917,\n",
      "        0.1879], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0859, 0.1927, 0.1265, 0.3438, 0.1129, 0.1362, 0.2168, 0.2185, 0.1104,\n",
      "        0.1538, 0.1085, 0.1462, 0.1840, 0.1146, 0.2335, 0.1729, 0.1803, 0.0872,\n",
      "        0.1483, 0.0599, 0.1777, 0.0883, 0.1319, 0.3591, 0.3758, 0.1294, 0.1127,\n",
      "        0.3080, 0.2070, 0.2054, 0.2128], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1388, 0.1223, 0.1448, 0.0918, 0.3071, 0.2103, 0.0524, 0.2172, 0.1743,\n",
      "        0.0972, 0.1389, 0.0865, 0.1560, 0.0893, 0.0969, 0.0897, 0.0956, 0.0649,\n",
      "        0.1490, 0.0532, 0.1467, 0.1469, 0.2011, 0.2052, 0.1112, 0.2325, 0.1304,\n",
      "        0.2313, 0.3076, 0.2836, 0.1219, 0.1288, 0.0728, 0.2770, 0.1479, 0.2035,\n",
      "        0.0859, 0.2183, 0.1586, 0.1664, 0.1882, 0.1318, 0.1308, 0.1381, 0.1758,\n",
      "        0.1004, 0.1631, 0.0904, 0.0897, 0.1777, 0.0742, 0.1187, 0.1482, 0.0904,\n",
      "        0.0333], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0.], device='cuda:0')\n",
      "tensor([0.0470, 0.1259, 0.1370, 0.1018, 0.1931, 0.1081, 0.2424, 0.2225, 0.2470,\n",
      "        0.1542, 0.1462, 0.0642, 0.4415, 0.1006, 0.0440, 0.1733, 0.1432, 0.1848,\n",
      "        0.5012, 0.1828, 0.0525, 0.0498, 0.4163, 0.1405, 0.1385, 0.1529, 0.0737,\n",
      "        0.1556, 0.3067, 0.3412, 0.0700, 0.1188, 0.0414, 0.0673, 0.1375, 0.2025,\n",
      "        0.1596, 0.1588, 0.3729, 0.3255, 0.1154, 0.1048], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1729, 0.2170, 0.0730, 0.1159, 0.2077, 0.0489, 0.1541, 0.1150, 0.1739,\n",
      "        0.1057, 0.1704, 0.2199, 0.1523, 0.0844, 0.1017, 0.1659, 0.0634, 0.1532,\n",
      "        0.1067, 0.0872, 0.0949, 0.1295, 0.1622, 0.1275, 0.1129, 0.1200, 0.1093,\n",
      "        0.0862, 0.0766, 0.2147, 0.0984, 0.1959, 0.1417], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.0668, 0.2323, 0.0560, 0.0884, 0.1886, 0.0603, 0.0741, 0.1078, 0.0872,\n",
      "        0.1689, 0.0508, 0.1548, 0.3500, 0.1248, 0.1780, 0.1229, 0.1641, 0.0933,\n",
      "        0.0926, 0.0849, 0.1304, 0.2382, 0.1638, 0.1813, 0.0448, 0.1184, 0.1433,\n",
      "        0.1071, 0.1906, 0.0792, 0.0434, 0.1124, 0.0929, 0.0942, 0.0545, 0.2087,\n",
      "        0.2345, 0.0391, 0.1591, 0.0830, 0.0710, 0.1094, 0.1918, 0.1414, 0.2004],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1395, 0.1565, 0.2237, 0.1339, 0.2566, 0.2576, 0.3669, 0.0833, 0.1565,\n",
      "        0.0773, 0.0991, 0.1183, 0.0752, 0.0565, 0.0693, 0.1734, 0.1770, 0.1951,\n",
      "        0.1997, 0.1348, 0.2834, 0.2097, 0.0482, 0.0344, 0.3405, 0.1198, 0.0677,\n",
      "        0.1793, 0.2221, 0.0209, 0.1071, 0.1448, 0.1321, 0.1095, 0.1065, 0.0865,\n",
      "        0.0376, 0.1254, 0.0904, 0.1434, 0.0422, 0.1847, 0.1168, 0.0671, 0.1852,\n",
      "        0.0433, 0.1744, 0.0446, 0.1178, 0.2328], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.1266, 0.2140, 0.1127, 0.1306, 0.1221, 0.2081, 0.1201, 0.2394, 0.2445,\n",
      "        0.2150, 0.1455, 0.1312, 0.0377, 0.1473, 0.2126, 0.1719, 0.1396, 0.1133,\n",
      "        0.0895, 0.1137, 0.0873, 0.0693, 0.1488, 0.0590, 0.1906, 0.1365, 0.0836,\n",
      "        0.2135, 0.0792, 0.3137, 0.1243, 0.1024], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.3700, 0.1099, 0.1357, 0.0332, 0.0368, 0.4223, 0.2282, 0.0709, 0.0920,\n",
      "        0.2787, 0.1072, 0.1810, 0.0613, 0.1323, 0.0879, 0.1734, 0.2230, 0.1704,\n",
      "        0.1567, 0.1689, 0.1588, 0.1328, 0.0905, 0.2509, 0.2994, 0.1343, 0.1585,\n",
      "        0.1337, 0.2111, 0.1278, 0.0844, 0.4354, 0.2540, 0.2061, 0.1660, 0.1013,\n",
      "        0.1469, 0.2346, 0.2270, 0.1535, 0.0794, 0.0809, 0.2304, 0.2210, 0.1232,\n",
      "        0.1542, 0.2189, 0.2728, 0.2889, 0.0672, 0.0870, 0.0781, 0.3033, 0.1272,\n",
      "        0.1365, 0.1263, 0.1809, 0.0966, 0.0735, 0.2059, 0.3115, 0.0765, 0.1676,\n",
      "        0.1447, 0.1259], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1087, 0.1272, 0.0960, 0.0720, 0.1708, 0.1915, 0.0396, 0.2022, 0.1286,\n",
      "        0.2274, 0.1142, 0.2035, 0.2605, 0.1599, 0.1162, 0.0491, 0.3178, 0.1643,\n",
      "        0.1083, 0.2326, 0.2333, 0.1573, 0.2079, 0.0973, 0.0476, 0.2850, 0.2159,\n",
      "        0.2240, 0.1659, 0.2616, 0.1433], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1659, 0.0819, 0.1358, 0.2508, 0.0718, 0.4258, 0.0767, 0.2336, 0.1015,\n",
      "        0.1407, 0.0776, 0.0965, 0.2136, 0.0820, 0.1596, 0.0469, 0.3811, 0.2008,\n",
      "        0.1443, 0.1828, 0.0898, 0.3836, 0.1250, 0.1802, 0.1404, 0.0801, 0.2722,\n",
      "        0.0737, 0.1609, 0.0616, 0.1004], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0959, 0.0820, 0.1165, 0.0641, 0.1067, 0.0891, 0.1631, 0.2322, 0.1472,\n",
      "        0.1020, 0.2292, 0.2404, 0.0894, 0.0940, 0.0667, 0.1271, 0.1388, 0.0928,\n",
      "        0.0905, 0.1049, 0.1221, 0.1756, 0.1028, 0.1271, 0.1397, 0.0987, 0.1189,\n",
      "        0.1836, 0.1606, 0.0531, 0.1510, 0.3956, 0.1002, 0.1748, 0.0385, 0.1252,\n",
      "        0.1033, 0.0790, 0.1316, 0.1460, 0.1388, 0.1027, 0.1506, 0.0746, 0.0926,\n",
      "        0.0920, 0.1823, 0.3324, 0.1052, 0.1676, 0.3688, 0.1197, 0.3634, 0.0670,\n",
      "        0.1102, 0.1782], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0')\n",
      "tensor([0.1456, 0.1455, 0.0530, 0.0815, 0.1452, 0.3160, 0.1155, 0.2446, 0.4095,\n",
      "        0.1311, 0.1441, 0.1642, 0.0973, 0.1441, 0.1080, 0.1978, 0.1307, 0.2248,\n",
      "        0.1964, 0.1455, 0.2303, 0.4171, 0.2824, 0.3662, 0.1587, 0.1725, 0.1089,\n",
      "        0.0883, 0.1507, 0.2817, 0.1402, 0.0741, 0.1250, 0.0917, 0.1398, 0.0971,\n",
      "        0.2495, 0.2545, 0.2447, 0.1360, 0.2434], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1164, 0.1026, 0.1972, 0.0900, 0.0367, 0.1877, 0.1466, 0.1073, 0.1191,\n",
      "        0.1903, 0.1957, 0.1116, 0.0921, 0.4153, 0.2846, 0.1403, 0.0864, 0.1944,\n",
      "        0.2511, 0.1921, 0.1487, 0.1042, 0.2685, 0.0456, 0.2577, 0.3296, 0.2242,\n",
      "        0.0662, 0.1175, 0.2186, 0.1626, 0.1088, 0.1593, 0.1888, 0.0630, 0.0766,\n",
      "        0.2325, 0.0478, 0.1451, 0.2595], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0685, 0.1420, 0.1532, 0.1970, 0.1250, 0.1108, 0.0636, 0.1168, 0.0783,\n",
      "        0.0548, 0.0904, 0.2172, 0.2389, 0.1823, 0.1037, 0.1654, 0.1150, 0.1663,\n",
      "        0.0957, 0.1956, 0.1715, 0.2837, 0.0904, 0.0908, 0.1306, 0.1894, 0.0627,\n",
      "        0.3247, 0.3562, 0.0885, 0.1001, 0.1393, 0.2260, 0.2867, 0.1394, 0.1037,\n",
      "        0.0876, 0.0996, 0.2077, 0.1732, 0.2229], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0893, 0.1104, 0.0951, 0.1148, 0.1775, 0.0433, 0.1463, 0.1695, 0.0721,\n",
      "        0.0397, 0.0561, 0.1662, 0.1899, 0.1742, 0.2679, 0.3079, 0.1096, 0.0918,\n",
      "        0.2625, 0.0421, 0.1332, 0.1672, 0.1061, 0.2892, 0.2090, 0.1371, 0.1338,\n",
      "        0.2536, 0.1017, 0.1108, 0.1534, 0.0636, 0.0582, 0.2302, 0.1572, 0.0181,\n",
      "        0.0835, 0.0598, 0.1045, 0.0857, 0.3261, 0.1719, 0.1834, 0.0873, 0.1109,\n",
      "        0.0879, 0.1879], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0767, 0.1867, 0.3934, 0.0734, 0.1425, 0.1729, 0.0713, 0.0687, 0.2068,\n",
      "        0.1238, 0.0946, 0.1793, 0.0810, 0.2413, 0.2264, 0.1186, 0.2030, 0.2249,\n",
      "        0.1101, 0.1160, 0.1978, 0.4293, 0.1345, 0.0858, 0.1283, 0.1644, 0.1403,\n",
      "        0.1749, 0.0622, 0.0990, 0.1203, 0.1881, 0.0592, 0.1304, 0.1665, 0.2444,\n",
      "        0.1179, 0.1070, 0.1351, 0.0913, 0.0828, 0.0987], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1061, 0.2477, 0.1008, 0.1315, 0.1267, 0.2416, 0.2258, 0.1384, 0.0435,\n",
      "        0.0973, 0.1295, 0.1053, 0.1192, 0.0871, 0.0942, 0.1986, 0.1561, 0.1366,\n",
      "        0.3449, 0.1915, 0.0765, 0.0468, 0.1400, 0.0451, 0.1571, 0.1089, 0.1518,\n",
      "        0.1908, 0.1973, 0.1139, 0.2476, 0.1617, 0.0368, 0.1479, 0.0846, 0.0529,\n",
      "        0.3055, 0.0755, 0.0358, 0.1307, 0.0626, 0.0803, 0.1875, 0.1196, 0.1550,\n",
      "        0.1776, 0.0634, 0.0745], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1682, 0.0941, 0.2307, 0.1348, 0.2241, 0.0909, 0.1105, 0.0932, 0.2200,\n",
      "        0.4148, 0.1788, 0.1535, 0.0460, 0.1329, 0.1675, 0.1772, 0.1641, 0.1271,\n",
      "        0.0751, 0.1915, 0.2805, 0.0583, 0.1081, 0.1732, 0.1399, 0.1789, 0.2035,\n",
      "        0.1560, 0.2540, 0.1362, 0.1955, 0.0695, 0.1418, 0.1158, 0.2300, 0.1202,\n",
      "        0.1062, 0.4330], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0')\n",
      "tensor([0.0950, 0.1130, 0.0753, 0.1608, 0.2449, 0.2337, 0.1013, 0.2052, 0.0720,\n",
      "        0.1315, 0.1041, 0.1930, 0.1255, 0.0844, 0.1016, 0.1764, 0.0868, 0.1018,\n",
      "        0.3303, 0.2661, 0.1066, 0.0393, 0.3562, 0.1758, 0.0754, 0.0706, 0.1925,\n",
      "        0.1187, 0.3247, 0.1092, 0.1552, 0.0977, 0.1440, 0.1306, 0.0935, 0.1471,\n",
      "        0.0886, 0.2454], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.], device='cuda:0')\n",
      "tensor([0.1502, 0.0784, 0.0361, 0.1805, 0.1950, 0.1372, 0.1122, 0.2065, 0.0764,\n",
      "        0.0962, 0.1140, 0.1533, 0.1089, 0.2357, 0.0844, 0.1807, 0.2683, 0.1154,\n",
      "        0.1739, 0.3084, 0.0704, 0.2285, 0.1324, 0.1806, 0.0473, 0.1760, 0.0769,\n",
      "        0.0988, 0.1143, 0.1836, 0.0528, 0.0677, 0.1739, 0.0707, 0.0543, 0.0882,\n",
      "        0.1977, 0.0553, 0.1005, 0.0970, 0.0875, 0.3824, 0.1673, 0.0704],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0674, 0.0660, 0.0545, 0.1685, 0.2367, 0.1145, 0.1588, 0.1524, 0.1749,\n",
      "        0.1142, 0.0616, 0.1060, 0.1638, 0.1039, 0.0446, 0.1505, 0.0830, 0.3775,\n",
      "        0.2132, 0.2650, 0.4443, 0.2626, 0.1155, 0.0580, 0.1286, 0.2640, 0.2389,\n",
      "        0.1156, 0.2014, 0.0461, 0.2236, 0.1697, 0.1721, 0.1864, 0.1355, 0.1821,\n",
      "        0.0908, 0.1230, 0.0638, 0.1738, 0.1711, 0.2540, 0.0869, 0.1440, 0.1477,\n",
      "        0.0738], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1623, 0.3852, 0.2247, 0.2002, 0.1238, 0.0974, 0.2080, 0.1793, 0.1433,\n",
      "        0.1036, 0.1423, 0.1624, 0.0873, 0.1838, 0.0977, 0.2665, 0.2182, 0.4006,\n",
      "        0.1648, 0.1440, 0.0868, 0.3303, 0.2213, 0.1111, 0.1860, 0.0688, 0.1893,\n",
      "        0.3011, 0.2328, 0.0893, 0.1713, 0.1564, 0.1920, 0.1711, 0.1514, 0.1475],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.1905, 0.1714, 0.2319, 0.0793, 0.0783, 0.1202, 0.0951, 0.1658, 0.4228,\n",
      "        0.1712, 0.1641, 0.0990, 0.1465, 0.1501, 0.1601, 0.1267, 0.1290, 0.0971,\n",
      "        0.1491, 0.1017, 0.1319, 0.2715, 0.1970, 0.1270, 0.0701, 0.2807, 0.0595,\n",
      "        0.1513, 0.1765, 0.2413, 0.2412, 0.1890, 0.1771, 0.1811, 0.1154, 0.1556,\n",
      "        0.0503, 0.1174, 0.1709, 0.1084, 0.1227, 0.0867, 0.0910, 0.1236, 0.1558],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1642, 0.1385, 0.1020, 0.1763, 0.0614, 0.1862, 0.0764, 0.1949, 0.1621,\n",
      "        0.0693, 0.3747, 0.2490, 0.1308, 0.1197, 0.0698, 0.0933, 0.0651, 0.1690,\n",
      "        0.1278, 0.0443, 0.0525, 0.1827, 0.0709, 0.2026, 0.1047, 0.1434, 0.3360,\n",
      "        0.1568, 0.2296, 0.1751, 0.4357, 0.0674, 0.2255, 0.1194, 0.1551, 0.2540,\n",
      "        0.1776, 0.1813, 0.1107, 0.0911, 0.1429, 0.1653, 0.0414, 0.0916, 0.1875,\n",
      "        0.0883, 0.1536], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.2215, 0.1201, 0.1815, 0.0983, 0.1858, 0.1116, 0.2918, 0.2119, 0.1711,\n",
      "        0.0751, 0.2920, 0.0737, 0.2136, 0.0990, 0.1025, 0.1481, 0.1146, 0.1858,\n",
      "        0.2047, 0.1893, 0.1207, 0.1013, 0.0806, 0.0833, 0.1341, 0.1197, 0.0797,\n",
      "        0.1871], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0503, 0.1721, 0.1661, 0.1147, 0.0967, 0.1807, 0.2847, 0.2063, 0.0561,\n",
      "        0.2220, 0.1135, 0.1177, 0.1779, 0.1493, 0.1748, 0.1747, 0.0599, 0.2906,\n",
      "        0.0739, 0.1219, 0.0570, 0.0420, 0.0760, 0.0605, 0.2539, 0.2689, 0.2801,\n",
      "        0.0543, 0.1608, 0.0845, 0.0877, 0.1722, 0.0924, 0.1478, 0.1626, 0.0796,\n",
      "        0.0624, 0.3383, 0.1162, 0.3378, 0.0684, 0.1535, 0.0371, 0.0451, 0.0630,\n",
      "        0.3794, 0.0844, 0.3787, 0.2880, 0.1591, 0.1237, 0.1297, 0.0663, 0.1279],\n",
      "       device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.1431, 0.1306, 0.1437, 0.0379, 0.1687, 0.1042, 0.2944, 0.1279, 0.1145,\n",
      "        0.0864, 0.0842, 0.0496, 0.3107, 0.2634, 0.0918, 0.1425, 0.1160, 0.1147,\n",
      "        0.1159, 0.1309, 0.1272, 0.1237, 0.0566, 0.2079, 0.0491, 0.0607, 0.1402,\n",
      "        0.0623, 0.1193, 0.0686, 0.2200, 0.1917, 0.1192, 0.1282, 0.1215, 0.0408,\n",
      "        0.0751, 0.2637, 0.1779, 0.1647, 0.1212, 0.0119, 0.1360, 0.1034, 0.2345,\n",
      "        0.1531], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1936, 0.3084, 0.3394, 0.1309, 0.2423, 0.0539, 0.1444, 0.1109, 0.0893,\n",
      "        0.1195, 0.1880, 0.0563, 0.1341, 0.1124, 0.1850, 0.1753, 0.0586, 0.1597,\n",
      "        0.3820, 0.1620, 0.0882, 0.2662, 0.0781, 0.0959, 0.0677, 0.0743, 0.0897,\n",
      "        0.1109, 0.2636, 0.1319, 0.1569, 0.1336, 0.1232], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.1786, 0.0866, 0.1594, 0.0924, 0.0782, 0.1872, 0.1131, 0.0927, 0.0388,\n",
      "        0.0666, 0.1939, 0.1332, 0.1229, 0.1879, 0.1746, 0.2647, 0.1143, 0.1041,\n",
      "        0.1298, 0.1592, 0.1321, 0.0741, 0.0664, 0.1284, 0.0854, 0.0750, 0.2019,\n",
      "        0.0362, 0.0719, 0.0733, 0.1026, 0.2041, 0.1710, 0.0442, 0.0489, 0.0844,\n",
      "        0.0830, 0.0595, 0.1257, 0.1395, 0.1892, 0.1561, 0.0915, 0.1109, 0.1058,\n",
      "        0.1902, 0.0465, 0.1243], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.1236, 0.0688, 0.0602, 0.0944, 0.1130, 0.1305, 0.1760, 0.1056, 0.1626,\n",
      "        0.0932, 0.1399, 0.1011, 0.1980, 0.2120, 0.1054, 0.1879, 0.1291, 0.2366,\n",
      "        0.1539, 0.0271, 0.2782, 0.1141, 0.2433, 0.1780, 0.1117, 0.0622, 0.1960,\n",
      "        0.0610, 0.2089, 0.0541, 0.0860, 0.1640, 0.4176, 0.0736, 0.1712, 0.2504,\n",
      "        0.0972, 0.2704, 0.1094, 0.0468, 0.2223, 0.0728, 0.2085, 0.1592, 0.1059,\n",
      "        0.2936, 0.2107], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([0.2579, 0.1043, 0.1147, 0.1854, 0.0930, 0.0829, 0.1920, 0.1075, 0.1622,\n",
      "        0.0507, 0.2167, 0.1973, 0.1116, 0.0849, 0.1119, 0.0980, 0.1227, 0.1288,\n",
      "        0.1305, 0.1295, 0.0897, 0.0559, 0.2851, 0.2211, 0.1058, 0.0889, 0.1314,\n",
      "        0.1303, 0.1293, 0.3744, 0.1853, 0.1989], device='cuda:0',\n",
      "       grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([0.3292, 0.0533, 0.1233, 0.1947, 0.1574, 0.1624, 0.1057, 0.0803, 0.1436,\n",
      "        0.1373, 0.1499, 0.1048, 0.1037, 0.0871, 0.0797, 0.1614, 0.3120, 0.0900,\n",
      "        0.0994, 0.4234, 0.1299, 0.1058, 0.1462, 0.1083, 0.1015, 0.1791, 0.1354,\n",
      "        0.1500, 0.1537, 0.1412, 0.1325, 0.0854, 0.3099, 0.0840, 0.1484, 0.3267,\n",
      "        0.2051, 0.2598, 0.0955, 0.0483, 0.1950, 0.1667, 0.0621, 0.0817, 0.1150,\n",
      "        0.4557, 0.1235, 0.1890, 0.2767, 0.1906, 0.1990, 0.1143, 0.1645, 0.2169,\n",
      "        0.1103, 0.1671, 0.0852], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0.], device='cuda:0')\n",
      "tensor([0.0732, 0.2448, 0.1538, 0.1628, 0.0437, 0.0786, 0.2126, 0.2725, 0.0752,\n",
      "        0.1466, 0.3619, 0.0608, 0.0361, 0.2143, 0.0687, 0.0807, 0.1723, 0.0712,\n",
      "        0.1647, 0.1648, 0.2363, 0.1639, 0.1689, 0.2220, 0.1121, 0.0187, 0.0625,\n",
      "        0.2895, 0.1260, 0.1549, 0.1019, 0.1217, 0.0619, 0.2252, 0.1457, 0.0754,\n",
      "        0.0675, 0.1996, 0.3832], device='cuda:0', grad_fn=<ExpBackward>) tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped training at 0.096045197740113 epochs due to keyboard interrupt.\n"
     ]
    }
   ],
   "source": [
    "l.train(nEpochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
